{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library versions:\n",
      "tensorflow:1.11.0\n",
      "pandas:0.23.4\n",
      "numpy:1.15.4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a0f71e5fd844e46831f42311a8b33b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## %matplotlib inline\n",
    "\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import importlib\n",
    "\n",
    "import customersupport.common\n",
    "import customersupport.common.utils\n",
    "import customersupport.evaluation.eval\n",
    "\n",
    "print('Library versions:')\n",
    "\n",
    "import tensorflow as tf\n",
    "print('tensorflow:{}'.format(tf.__version__))\n",
    "import pandas as pd\n",
    "print('pandas:{}'.format(pd.__version__))\n",
    "# import sklearn\n",
    "# print('sklearn:{}'.format(sklearn.__version__))\n",
    "# import nltk\n",
    "# print('nltk:{}'.format(nltk.__version__))\n",
    "import numpy as np\n",
    "print('numpy:{}'.format(np.__version__))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tqdm import tqdm_notebook as tqdm  # Special jupyter notebook progress bar\n",
    "\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "from datetime import datetime\n",
    "\n",
    "from customersupport.common.vocab import VocabHolder\n",
    "from customersupport.common.dataset import CustomerSupportDataset\n",
    "\n",
    "from customersupport.evaluation.eval import evaluate_words_index, format_metrics, get_evaluation_conf, strip_punkt\n",
    "\n",
    "importlib.reload(customersupport.common.vocab)\n",
    "importlib.reload(customersupport.common.dataset)\n",
    "importlib.reload(customersupport.common.utils)\n",
    "importlib.reload(customersupport.evaluation.eval)\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "tqdm().pandas()  # Enable tracking of progress in dataframe `apply` calls\n",
    "\n",
    "tqdm.monitor_interval = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.physical_device_desc for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### 8192 - large enough for demonstration, larger values make network training slower\n",
    "MAX_VOCAB_SIZE = 2**13\n",
    "\n",
    "# seq2seq generally relies on fixed length message vectors - longer messages provide more info\n",
    "# but result in slower training and larger networks\n",
    "#MAX_MESSAGE_LEN = 50\n",
    "\n",
    "hparams = tf.contrib.training.HParams(\n",
    "    # Larger batch sizes generally reach the average response faster, but small batch sizes are\n",
    "    # required for the model to learn nuanced responses.  Also, GPU memory limits max batch size.\n",
    "    batch_size=64,\n",
    "    encoder_length=60,\n",
    "    decoder_length=70,\n",
    "    src_vocab_size=MAX_VOCAB_SIZE,\n",
    "    # Embedding size for words - gives a trade off between expressivity of words and network size\n",
    "    embedding_size=200,\n",
    "    tgt_vocab_size=MAX_VOCAB_SIZE,\n",
    "    # Helps regularize network and prevent overfitting.\n",
    "    # High learning rate helps model reach average response faster, but can make it hard to\n",
    "    # converge on nuanced responses\n",
    "    learning_rate=5e-04,  #0.0005,\n",
    "    max_gradient_norm=5.0,\n",
    "    l2_norm = True,\n",
    "    beam_width = 10,\n",
    "    d = 64,\n",
    "    nh = 4,\n",
    "    max_epochs=15,\n",
    "    dropout=0.1,\n",
    "    use_glove=True,\n",
    "    l2_reg=0.,\n",
    "    glove_path=#None,\n",
    "    '/home/momchil/Storage/Projects/Python/Data/glove.twitter.27B/glove.twitter.27B.200d.txt',\n",
    "    tweets_path=\n",
    "    '/home/momchil/Storage/Projects/Python/Data/customer-support-on-twitter/twcs-conv_ids_clean.csv',\n",
    "    # Ngram count for ROUGE and BLEU\n",
    "    max_order = 2,\n",
    "    train_size=0.8,\n",
    "    decay_rate=0.99,\n",
    "    train_time_diff=5.0,\n",
    "    first_day=0,\n",
    "    last_day=60,\n",
    "    evaluation_metrics=[\n",
    "        \"bleu\", \"rouge_l\", \"embedding_average\", \"vector_extrema\",\n",
    "        \"greedy_matching\"\n",
    "    ],\n",
    "    training_metrics=[\n",
    "        \"bleu\", \"rouge_l\", \"embedding_average\", \"vector_extrema\",\n",
    "        \"greedy_matching\"\n",
    "    ],\n",
    "    companies=['AppleSupport'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done support_author (984679, 9)\n",
      "Replacing anonymized screen names in X...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524f40b635fa4c9fbe359acbb7425e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105179), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing anonymized screen names in Y...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec49679d95c4d638b66fc2d89b11766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105179), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 1min, sys: 1.17 s, total: 1min 1s\n",
      "Wall time: 56.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cs_data = CustomerSupportDataset(hparams)\n",
    "\n",
    "#& (y_text.str.contains('help') ^ True)\n",
    "#['direct message', 'is fixed in a future software update']\n",
    "cs_data.process_utterances(masks=['direct message'], append_context=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded glove\n",
      "Loaded w2v\n"
     ]
    }
   ],
   "source": [
    "voc_holder = VocabHolder(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CountVectorizer on X and Y text data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8d764233a84174879acf08d6aca9bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=49626), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of known words 7378\n",
      "Learned vocab of 8192 items.\n",
      "Calculating word indexes for X...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39dee805b78d479c9cb40773922a0330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=49626), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating word indexes for Y...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b932d794b90045aa9b39fcf5cc67120f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=49626), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data of shape (45582, 60) and test data of shape (4044, 70).\n",
      "count    45582.000000\n",
      "mean         1.000000\n",
      "std          0.141677\n",
      "min          0.740038\n",
      "25%          0.883758\n",
      "50%          1.021893\n",
      "75%          1.097074\n",
      "max          1.286219\n",
      "dtype: float64\n",
      "count    4044.000000\n",
      "mean        1.000000\n",
      "std         0.014701\n",
      "min         0.972407\n",
      "25%         0.988713\n",
      "50%         1.001299\n",
      "75%         1.011627\n",
      "max         1.022508\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "analyzer = voc_holder.fit(cs_data.x_text, cs_data.y_text, hparams.src_vocab_size)\n",
    "\n",
    "cs_data.text_to_vec(hparams, voc_holder)\n",
    "cs_data.train_test_split(hparams, do_random=False)\n",
    "\n",
    "train_x = cs_data.train_x\n",
    "train_y = cs_data.train_y\n",
    "\n",
    "test_x = cs_data.test_x\n",
    "test_y = cs_data.test_y\n",
    "\n",
    "train_weights = cs_data.train_weights\n",
    "test_weights = cs_data.test_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n",
      "INFO:tensorflow:Downloading TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n",
      "INFO:tensorflow:Downloaded TF-Hub Module 'https://tfhub.dev/google/elmo/2'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4def00c951d64c7a96dabc5060888d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "def validate_elmo(elmo_weights, voc_holder, word):\n",
    "    elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
    "    embeddings = elmo(\n",
    "                inputs={\n",
    "                    \"tokens\": [[word]],\n",
    "                    \"sequence_len\": [1]\n",
    "                },\n",
    "                signature=\"tokens\",\n",
    "                as_dict=True)[\"elmo\"]\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        elmo_pred = sess.run(embeddings).reshape(1024)\n",
    "    embedding = elmo_weights[voc_holder.vocab[word]]\n",
    "    \n",
    "    np.testing.assert_array_almost_equal(elmo_pred, embedding, decimal=6)\n",
    "\n",
    "def export_elmo(vocab_holder):\n",
    "    elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
    "    \n",
    "    words = [\"\"] * len(voc_holder.reverse_vocab)\n",
    "    for i, w in voc_holder.reverse_vocab.items():\n",
    "        words[i] = w\n",
    "        \n",
    "    # ELMo uses those 3\n",
    "    words[customersupport.common.utils.START] = '<S>'\n",
    "    words[customersupport.common.utils.PAD] = '</S>'\n",
    "    words[customersupport.common.utils.UNK] = '<UNK>'\n",
    "    \n",
    "    words = np.array(words, dtype=np.str).reshape(-1, 512, 1)\n",
    "\n",
    "    elmo_weights = []\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for tokens_input in tqdm(words):\n",
    "            embeddings = elmo(\n",
    "                inputs={\n",
    "                    \"tokens\": tokens_input,\n",
    "                    \"sequence_len\": np.ones(tokens_input.shape[0])\n",
    "                },\n",
    "                signature=\"tokens\",\n",
    "                as_dict=True)[\"elmo\"]\n",
    "            e = sess.run(embeddings)\n",
    "            elmo_weights.append(e.reshape(-1, 1024))\n",
    "\n",
    "        elmo_weights = np.array(elmo_weights).reshape(-1, 1024)\n",
    "        return elmo_weights\n",
    "\n",
    "elmo = export_elmo(voc_holder)\n",
    "elmo[customersupport.common.utils.PAD] = np.zeros(elmo.shape[-1], dtype=np.float32)\n",
    "\n",
    "validate_elmo(elmo, voc_holder, \"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17ba56c49cc34068bc071bff239f48b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8192), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def export_vocab(voc_holder):\n",
    "    with open(\"/home/momchil/Storage/Projects/Python/Data/multi_cased_L-12_H-768_A-12/vocab.txt\", \"w\") as f:\n",
    "        for l in map(lambda x: voc_holder.reverse_vocab[x], range(MAX_VOCAB_SIZE)):\n",
    "            f.write(l + \"\\n\")\n",
    "\n",
    "def export_bert(vocab_holder):\n",
    "    \n",
    "    def sum_per_layer(data, i):\n",
    "        return np.sum([t['layers'][i]['values'] for t in data['features'][1:]], 0)\n",
    "    \n",
    "    words = [\"\"] * len(voc_holder.reverse_vocab)\n",
    "    for i, w in voc_holder.reverse_vocab.items():\n",
    "        words[i] = w\n",
    "        \n",
    "    # BERT uses those 3\n",
    "    words[customersupport.common.utils.START] = '<S>'\n",
    "    words[customersupport.common.utils.PAD] = '[PAD]'\n",
    "    words[customersupport.common.utils.UNK] = '[UNK]'\n",
    "    \n",
    "    bert_weights = []\n",
    "    with open('/home/momchil/Storage/Projects/Python/Data/uncased_L-12_H-768_A-12/output.jsonl') as f:\n",
    "#         for i in range(2000): \n",
    "#             f.readline()\n",
    "        for i, w in enumerate(tqdm(words)):\n",
    "            data = json.loads(str(f.readline()))\n",
    "#             weights = np.sum([data['features'][i]['layers'][0]['values'] for i in range(len(data['features']))], 0)\n",
    "#             weights = data['features'][0]['layers'][0]['values']\n",
    "#             print( data['features'][0]['token'])\n",
    "            weights = sum_per_layer(data, 0)\n",
    "            for i in range(1, len(data['features'][0]['layers'])):\n",
    "#                 weights = np.concatenate((weights, sum_per_layer(data, i)))\n",
    "                weights += sum_per_layer(data, i)\n",
    "            bert_weights.append(weights)\n",
    "    \n",
    "    return np.array(bert_weights, dtype=np.float32)\n",
    "\n",
    "bert = export_bert(voc_holder)\n",
    "bert[customersupport.common.utils.PAD] = np.zeros(bert.shape[-1], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.util import nest\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import clip_ops\n",
    "\n",
    "def batch_dot(x, y, axes=None):\n",
    "    \"\"\"Copy from keras==2.0.6\n",
    "    Batchwise dot product.\n",
    "    `batch_dot` is used to compute dot product of `x` and `y` when\n",
    "    `x` and `y` are data in batch, i.e. in a shape of\n",
    "    `(batch_size, :)`.\n",
    "    `batch_dot` results in a tensor or variable with less dimensions\n",
    "    than the input. If the number of dimensions is reduced to 1,\n",
    "    we use `expand_dims` to make sure that ndim is at least 2.\n",
    "    # Arguments\n",
    "        x: Keras tensor or variable with `ndim >= 2`.\n",
    "        y: Keras tensor or variable with `ndim >= 2`.\n",
    "        axes: list of (or single) int with target dimensions.\n",
    "            The lengths of `axes[0]` and `axes[1]` should be the same.\n",
    "    # Returns\n",
    "        A tensor with shape equal to the concatenation of `x`'s shape\n",
    "        (less the dimension that was summed over) and `y`'s shape\n",
    "        (less the batch dimension and the dimension that was summed over).\n",
    "        If the final rank is 1, we reshape it to `(batch_size, 1)`.\n",
    "    \"\"\"\n",
    "    if isinstance(axes, int):\n",
    "        axes = (axes, axes)\n",
    "    x_ndim = ndim(x)\n",
    "    y_ndim = ndim(y)\n",
    "    if x_ndim > y_ndim:\n",
    "        diff = x_ndim - y_ndim\n",
    "        y = tf.reshape(y, tf.concat([tf.shape(y), [1] * (diff)], axis=0))\n",
    "    elif y_ndim > x_ndim:\n",
    "        diff = y_ndim - x_ndim\n",
    "        x = tf.reshape(x, tf.concat([tf.shape(x), [1] * (diff)], axis=0))\n",
    "    else:\n",
    "        diff = 0\n",
    "    if ndim(x) == 2 and ndim(y) == 2:\n",
    "        if axes[0] == axes[1]:\n",
    "            out = tf.reduce_sum(tf.multiply(x, y), axes[0])\n",
    "        else:\n",
    "            out = tf.reduce_sum(tf.multiply(tf.transpose(x, [1, 0]), y), axes[1])\n",
    "    else:\n",
    "        if axes is not None:\n",
    "            adj_x = None if axes[0] == ndim(x) - 1 else True\n",
    "            adj_y = True if axes[1] == ndim(y) - 1 else None\n",
    "        else:\n",
    "            adj_x = None\n",
    "            adj_y = None\n",
    "        out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n",
    "    if diff:\n",
    "        if x_ndim > y_ndim:\n",
    "            idx = x_ndim + y_ndim - 3\n",
    "        else:\n",
    "            idx = x_ndim - 1\n",
    "        out = tf.squeeze(out, list(range(idx, idx + diff)))\n",
    "    if ndim(out) == 1:\n",
    "        out = tf.expand_dims(out, 1)\n",
    "    return out\n",
    "\n",
    "def ndim(x):\n",
    "    \"\"\"Copied from keras==2.0.6\n",
    "    Returns the number of axes in a tensor, as an integer.\n",
    "    # Arguments\n",
    "        x: Tensor or variable.\n",
    "    # Returns\n",
    "        Integer (scalar), number of axes.\n",
    "    # Examples\n",
    "    ```python\n",
    "        >>> from keras import backend as K\n",
    "        >>> inputs = K.placeholder(shape=(2, 4, 5))\n",
    "        >>> val = np.array([[1, 2], [3, 4]])\n",
    "        >>> kvar = K.variable(value=val)\n",
    "        >>> K.ndim(inputs)\n",
    "        3\n",
    "        >>> K.ndim(kvar)\n",
    "        2\n",
    "    ```\n",
    "    \"\"\"\n",
    "    dims = x.get_shape()._dims\n",
    "    if dims is not None:\n",
    "        return len(dims)\n",
    "    return None\n",
    "\n",
    "def dot(x, y):\n",
    "    \"\"\"Modified from keras==2.0.6\n",
    "    Multiplies 2 tensors (and/or variables) and returns a *tensor*.\n",
    "    When attempting to multiply a nD tensor\n",
    "    with a nD tensor, it reproduces the Theano behavior.\n",
    "    (e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`)\n",
    "    # Arguments\n",
    "        x: Tensor or variable.\n",
    "        y: Tensor or variable.\n",
    "    # Returns\n",
    "        A tensor, dot product of `x` and `y`.\n",
    "    \"\"\"\n",
    "    if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):\n",
    "        x_shape = []\n",
    "        for i, s in zip(x.get_shape().as_list(), tf.unstack(tf.shape(x))):\n",
    "            if i is not None:\n",
    "                x_shape.append(i)\n",
    "            else:\n",
    "                x_shape.append(s)\n",
    "        x_shape = tuple(x_shape)\n",
    "        y_shape = []\n",
    "        for i, s in zip(y.get_shape().as_list(), tf.unstack(tf.shape(y))):\n",
    "            if i is not None:\n",
    "                y_shape.append(i)\n",
    "            else:\n",
    "                y_shape.append(s)\n",
    "        y_shape = tuple(y_shape)\n",
    "        y_permute_dim = list(range(ndim(y)))\n",
    "        y_permute_dim = [y_permute_dim.pop(-2)] + y_permute_dim\n",
    "        xt = tf.reshape(x, [-1, x_shape[-1]])\n",
    "        yt = tf.reshape(tf.transpose(y, perm=y_permute_dim), [y_shape[-2], -1])\n",
    "        return tf.reshape(tf.matmul(xt, yt),\n",
    "                          x_shape[:-1] + y_shape[:-2] + y_shape[-1:])\n",
    "    if isinstance(x, tf.SparseTensor):\n",
    "        out = tf.sparse_tensor_dense_matmul(x, y)\n",
    "    else:\n",
    "        out = tf.matmul(x, y)\n",
    "    return out\n",
    "    \n",
    "initializer = lambda: tf.contrib.layers.variance_scaling_initializer(factor=1.0,\n",
    "                                                             mode='FAN_AVG',\n",
    "                                                             uniform=True,\n",
    "                                                             dtype=tf.float32)\n",
    "initializer_relu = lambda: tf.contrib.layers.variance_scaling_initializer(factor=2.0,\n",
    "                                                             mode='FAN_IN',\n",
    "                                                             uniform=False,\n",
    "                                                             dtype=tf.float32)\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale = 3e-7)\n",
    "\n",
    "def optimized_trilinear_for_attention(args, c_maxlen, q_maxlen, input_keep_prob=1.0,\n",
    "    scope='efficient_trilinear',\n",
    "    bias_initializer=tf.zeros_initializer(),\n",
    "    kernel_initializer=initializer()):\n",
    "    assert len(args) == 2, \"just use for computing attention with two input\"\n",
    "    arg0_shape = args[0].get_shape().as_list()\n",
    "    arg1_shape = args[1].get_shape().as_list()\n",
    "    if len(arg0_shape) != 3 or len(arg1_shape) != 3:\n",
    "        raise ValueError(\"`args` must be 3 dims (batch_size, len, dimension)\")\n",
    "    if arg0_shape[2] != arg1_shape[2]:\n",
    "        raise ValueError(\"the last dimension of `args` must equal\")\n",
    "    arg_size = arg0_shape[2]\n",
    "    dtype = args[0].dtype\n",
    "    droped_args = [tf.nn.dropout(arg, input_keep_prob) for arg in args]\n",
    "    with tf.variable_scope(scope):\n",
    "        weights4arg0 = tf.get_variable(\n",
    "            \"linear_kernel4arg0\", [arg_size, 1],\n",
    "            dtype=dtype,\n",
    "            regularizer=regularizer,\n",
    "            initializer=kernel_initializer)\n",
    "        weights4arg1 = tf.get_variable(\n",
    "            \"linear_kernel4arg1\", [arg_size, 1],\n",
    "            dtype=dtype,\n",
    "            regularizer=regularizer,\n",
    "            initializer=kernel_initializer)\n",
    "        weights4mlu = tf.get_variable(\n",
    "            \"linear_kernel4mul\", [1, 1, arg_size],\n",
    "            dtype=dtype,\n",
    "            regularizer=regularizer,\n",
    "            initializer=kernel_initializer)\n",
    "        biases = tf.get_variable(\n",
    "            \"linear_bias\", [1],\n",
    "            dtype=dtype,\n",
    "            regularizer=regularizer,\n",
    "            initializer=bias_initializer)\n",
    "        subres0 = tf.tile(dot(droped_args[0], weights4arg0), [1, 1, q_maxlen])\n",
    "        subres1 = tf.tile(tf.transpose(dot(droped_args[1], weights4arg1), perm=(0, 2, 1)), [1, c_maxlen, 1])\n",
    "        subres2 = batch_dot(droped_args[0] * weights4mlu, tf.transpose(droped_args[1], perm=(0, 2, 1)))\n",
    "        res = subres0 + subres1 + subres2\n",
    "        tf.nn.bias_add(res, tf.tile(biases, [q_maxlen]))\n",
    "        \n",
    "    return res\n",
    "\n",
    "def context2query(c: tf.Tensor, q: tf.Tensor, mask_c: tf.Tensor, mask_q: tf.Tensor, input_keep_prob: float):\n",
    "    with tf.variable_scope(\"Context_to_Query_Attention_Layer\"):\n",
    "        S = optimized_trilinear_for_attention([c, q], tf.shape(c)[1], tf.shape(q)[1], input_keep_prob)\n",
    "        S = mask_matrix(mask_q, S, tf.shape(c)[1])\n",
    "\n",
    "        S_ = tf.nn.softmax(S)\n",
    "        S_ *= tf.tile(tf.expand_dims(mask_c, -1), [1, 1, tf.shape(q)[1]]) \n",
    "        S_T = tf.transpose(tf.nn.softmax(S, axis = 1),(0,2,1))\n",
    "        \n",
    "        c2q = tf.matmul(S_, q)\n",
    "        q2c = tf.matmul(tf.matmul(S_, S_T), c)\n",
    "        attention_outputs = [c, c2q, c * c2q, c * q2c, S_]\n",
    "        \n",
    "        return attention_outputs\n",
    "    \n",
    "def linear(context: tf.Tensor, c_maxlen):\n",
    "    with tf.variable_scope(\"Linear\"):\n",
    "        wl = tf.get_variable(\"Wl\", shape=[1, c_maxlen], \n",
    "                             initializer=tf.contrib.layers.xavier_initializer())\n",
    "        out = tf.matmul(tf.tile(tf.expand_dims(wl, 0), [tf.shape(context)[0], 1, 1]), context)\n",
    "        \n",
    "        return tf.squeeze(out)\n",
    "    \n",
    "def embed_tensor(inputs, pretrained_embs, name, trainable=False):\n",
    "\n",
    "    train_embeddings = tf.get_variable(\n",
    "        name=name,\n",
    "        shape=[hparams.tgt_vocab_size - len(voc_holder.glove_weights), hparams.embedding_size],\n",
    "        initializer=tf.random_uniform_initializer(-0.04, 0.04),\n",
    "        trainable=True)\n",
    "    \n",
    "    embeddings = tf.concat(\n",
    "        [train_embeddings, pretrained_embs], axis=0)\n",
    "\n",
    "    return tf.nn.embedding_lookup(embeddings, inputs), embeddings\n",
    "\n",
    "def parametric_relu(_x):\n",
    "    alphas = tf.get_variable('alpha', _x.get_shape()[-1],\n",
    "                       initializer=initializer_relu(),\n",
    "                        dtype=tf.float32)\n",
    "    pos = tf.nn.relu(_x)\n",
    "    neg = alphas * (_x - abs(_x)) * 0.5\n",
    "\n",
    "    return pos + neg\n",
    "\n",
    "def gelu_fast(_x):\n",
    "    return 0.5 * _x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (_x + 0.044715 * tf.pow(_x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_fn_builder(x, y,  is_training, negatives):\n",
    "    import math\n",
    "    def cosine_similarity(v1, v2):\n",
    "\n",
    "        mx = hparams.src_vocab_size # max(np.max(v1), np.max(v2)) + 1\n",
    "        v1_tmp = np.zeros(mx)\n",
    "        v1_tmp[v1] = 1.\n",
    "        v1 = v1_tmp\n",
    "\n",
    "        v2_tmp = np.zeros(mx)\n",
    "        v2_tmp[v2] = 1.\n",
    "        v2 = v2_tmp\n",
    "\n",
    "        return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))      \n",
    "    \n",
    "    def data_generator():    \n",
    "        while True:\n",
    "            i, it = np.random.randint(0, len(x), 2)\n",
    "            if not negatives or np.random.binomial(1, 0.5, 1)[0] == 0:\n",
    "                it = i\n",
    "                sim = 1.\n",
    "            else:\n",
    "                sim = cosine_similarity(y[i], y[it])\n",
    "                \n",
    "            feed_dict = {}\n",
    "            feed_dict['qry'] = x[i]\n",
    "            feed_dict['ctx'] = y[it]\n",
    "            p = [float(sim > .7)]\n",
    "            \n",
    "            yield feed_dict, p\n",
    "            \n",
    "    def _decode_record(ctx, qry, p):\n",
    "        feed_dict = {}\n",
    "        feed_dict['qry'] = qry\n",
    "        feed_dict['ctx'] = ctx\n",
    "        labels = p\n",
    "        \n",
    "        return feed_dict, labels\n",
    "    \n",
    "    def input_fn(batch_size):\n",
    "\n",
    "        d = tf.data.Dataset.from_generator(\n",
    "            data_generator, ({'qry': tf.int32, 'ctx': tf.int32}, tf.float32),\n",
    "            output_shapes=({'qry': (hparams.encoder_length), 'ctx': (hparams.decoder_length)}, (1)))\n",
    "        \n",
    "        if is_training:\n",
    "            d = d.shuffle(300)\n",
    "            d = d.repeat()\n",
    "        \n",
    "        d = d.batch(batch_size)\n",
    "        \n",
    "        return d.make_one_shot_iterator().get_next()\n",
    "        \n",
    "    return input_fn\n",
    "\n",
    "def eval_input_fn_builder(questions, candidates):\n",
    "    \n",
    "    def data_generator():\n",
    "        feed_dict = {}\n",
    "        for q, cl in zip(questions, candidates):\n",
    "            feed_dict['ctx'] = np.array([voc_holder.to_word_idx(c, c_maxlen) for c in cl.split(\"@ @ @\")])\n",
    "            feed_dict['qry'] = np.tile(q, [feed_dict['ctx'].shape[0], 1])\n",
    "            \n",
    "            yield feed_dict\n",
    "            \n",
    "    def map_fn(feed_dict):\n",
    "        feed_dict['qry'] = tf.reshape(feed_dict['qry'], ((-1, hparams.encoder_length)))\n",
    "        feed_dict['ctx'] = tf.reshape(feed_dict['ctx'], ((-1, hparams.decoder_length)))\n",
    "        \n",
    "        return feed_dict\n",
    "       \n",
    "    def input_fn(batch_size):\n",
    "        d = tf.data.Dataset.from_generator(data_generator, ({'qry': tf.int32, 'ctx': tf.int32}),\n",
    "            output_shapes=({'qry': (None, hparams.encoder_length), 'ctx': (None, hparams.decoder_length)}))\n",
    "        \n",
    "        d = d.batch(batch_size)\n",
    "        d = d.map(map_fn)\n",
    "        \n",
    "        return d.make_one_shot_iterator().get_next()\n",
    "    return input_fn\n",
    "\n",
    "input_fn = input_fn_builder(train_x, train_y, True, True)\n",
    "test_input_fn = input_fn_builder(test_x, test_y, False, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn_builder(voc_holder, hparams, emb_weights):    \n",
    "    def model_fn(features, labels, mode, params):\n",
    "\n",
    "        from QANet.layers import residual_block, highway, conv, mask_logits, trilinear, \\\n",
    "            total_params#, optimized_trilinear_for_attention\n",
    "        is_training = (mode == tf.estimator.ModeKeys.TRAIN)\n",
    "        \n",
    "        qry = features[\"qry\"]\n",
    "        ctx = features[\"ctx\"]\n",
    "        \n",
    "        c_maxlen = tf.shape(ctx)[-1]\n",
    "        q_maxlen = tf.shape(qry)[-1]\n",
    "        batch_size = tf.shape(qry)[0]\n",
    "\n",
    "        dropout = hparams.dropout if is_training else 0.0 \n",
    "        #tf.placeholder_with_default(0.0, (), name=\"dropout\")\n",
    "\n",
    "        c_mask = tf.cast(ctx, tf.bool)\n",
    "        q_mask = tf.cast(qry, tf.bool)\n",
    "\n",
    "        c_len = tf.reduce_sum(tf.cast(c_mask, tf.int32), axis=1)\n",
    "        q_len = tf.reduce_sum(tf.cast(q_mask, tf.int32), axis=1)\n",
    "\n",
    "        with tf.variable_scope(\"Input_Embedding_Layer\"):\n",
    "        \n",
    "            if (hparams.use_glove):\n",
    "                pretrained_embs = tf.get_variable(\n",
    "                    name=\"embs_pretrained\",\n",
    "                    initializer=tf.constant_initializer(\n",
    "                       voc_holder.glove_weights, dtype=tf.float32),\n",
    "                    shape=voc_holder.glove_weights.shape,\n",
    "                    trainable=False)\n",
    "                _, emb_tensor = \\\n",
    "                    embed_tensor(qry, pretrained_embs, \"embedding_encoder_glove\")\n",
    "            else:\n",
    "                emb_tensor = tf.convert_to_tensor(emb_weights)\n",
    "\n",
    "            c_emb_ = tf.nn.dropout(tf.nn.embedding_lookup(emb_tensor, ctx), 1.0 - dropout)\n",
    "            q_emb_ = tf.nn.dropout(tf.nn.embedding_lookup(emb_tensor, qry), 1.0 - dropout)\n",
    "\n",
    "            c_emb = highway(c_emb_, size = hparams.d, scope = \"highway\", dropout = dropout, reuse = None)\n",
    "            q_emb = highway(q_emb_, size = hparams.d, scope = \"highway\", dropout = dropout, reuse = True)\n",
    "\n",
    "        with tf.variable_scope(\"Embedding_Encoder_Layer\"):\n",
    "            c = residual_block(inputs=c_emb,\n",
    "                num_blocks = 1,\n",
    "                num_conv_layers = 4,\n",
    "                kernel_size = 7,\n",
    "                mask = c_mask,\n",
    "                num_filters = hparams.d,\n",
    "                num_heads = hparams.nh,\n",
    "                seq_len = c_len,\n",
    "                scope = \"Encoder_Residual_Block\",\n",
    "                bias = False,\n",
    "                dropout = dropout)\n",
    "\n",
    "            q = residual_block(inputs=q_emb,\n",
    "                num_blocks = 1,\n",
    "                num_conv_layers = 4,\n",
    "                kernel_size = 7,\n",
    "                mask = q_mask,\n",
    "                num_filters = hparams.d,\n",
    "                num_heads = hparams.nh,\n",
    "                seq_len = q_len,\n",
    "                scope = \"Encoder_Residual_Block\",\n",
    "                reuse = True, # Share the weights between passage and question\n",
    "                bias = False,\n",
    "                dropout = dropout)\n",
    "\n",
    "        with tf.variable_scope(\"Context_to_Query_Attention_Layer\"):\n",
    "            S = optimized_trilinear_for_attention([c, q], c_maxlen, q_maxlen, input_keep_prob = 1.0 - dropout)\n",
    "            mask_q = tf.expand_dims(q_mask, 1)\n",
    "            S_ = tf.nn.softmax(mask_logits(S, mask = mask_q))\n",
    "            mask_c = tf.expand_dims(c_mask, 2)\n",
    "            S_T = tf.transpose(tf.nn.softmax(mask_logits(S, mask = mask_c), axis = 1),(0,2,1))\n",
    "            c2q = tf.matmul(S_, q)\n",
    "            q2c = tf.matmul(tf.matmul(S_, S_T), c)\n",
    "            attention_outputs = [c, c2q, c * c2q, c * q2c]\n",
    "\n",
    "        with tf.variable_scope(\"Model_Encoder_Layer\"):\n",
    "            inputs = tf.concat(attention_outputs, axis = -1)\n",
    "            enc = [conv(inputs, hparams.d, name = \"input_projection\")]\n",
    "            for i in range(2):\n",
    "                if i % 2 == 0: # dropout every 2 blocks\n",
    "                    enc[i] = tf.nn.dropout(enc[i], 1.0 - dropout)\n",
    "                enc.append(\n",
    "                    residual_block(enc[i],\n",
    "                        num_blocks = 7,\n",
    "                        num_conv_layers = 2,\n",
    "                        kernel_size = 5,\n",
    "                        mask = c_mask,\n",
    "                        num_filters = hparams.d,\n",
    "                        num_heads = hparams.nh,\n",
    "                        seq_len = c_len,\n",
    "                        scope = \"Model_Encoder\",\n",
    "                        bias = False,\n",
    "                        reuse = True if i > 0 else None,\n",
    "                        dropout = dropout)\n",
    "                    )\n",
    "        with tf.variable_scope(\"Output_Layer\"):\n",
    "            proj_logits = tf.squeeze(conv(tf.concat([enc[1], enc[2]],axis = -1),1, bias = False, name = \"first_logits\"),-1)\n",
    "#             proj_logits = tf.squeeze(conv(enc[1], 1, bias = False, name = \"first_logits\"), -1)\n",
    "#             proj_logits = tf.concat([proj_logits, \n",
    "#                                      batch_dot(tf.reduce_max(tf.abs(q_emb), 1), tf.reduce_max(tf.abs(c_emb), 1), 1),\n",
    "#                                      tf.reduce_mean(q_emb_, 1),\n",
    "#                                      tf.reduce_mean(c_emb_, 1)\n",
    "# #         #                              tf.reduce_max(c_emb, 1),\n",
    "# #         #                              tf.reduce_max(q_emb, 1),\n",
    "# #         #                              tf.reduce_min(c_emb, 1),\n",
    "# #         #                              tf.reduce_min(q_emb, 1),\n",
    "# #         #                              tf.reshape(tf.reduce_sum(tf.to_float(tf.equal(ctx, 1)), 1), (-1, 1)),\n",
    "# #         #                              tf.reshape(tf.reduce_sum(tf.to_float(tf.equal(qry, 1)), 1), (-1, 1)),\n",
    "# #         #                              tf.reduce_max(tf.one_hot(ctx, MAX_VOCAB_SIZE, on_value=1.0, off_value=0.0, axis =-1), 1),\n",
    "# #         #                              tf.reduce_max(tf.one_hot(qry, MAX_VOCAB_SIZE, on_value=1.0, off_value=0.0, axis =-1), 1)\n",
    "#                                     ], 1)\n",
    "            \n",
    "#             proj_logits = tf.nn.dropout(proj_logits, 1.0 - dropout)\n",
    "#             proj_logits = tf.layers.dense(proj_logits, hparams.d * 2, kernel_initializer=initializer(), \n",
    "#                                           activation=gelu_fast, kernel_regularizer=regularizer)\n",
    "\n",
    "            proj_logits = tf.nn.dropout(proj_logits, 1.0 - dropout)\n",
    "            logits = tf.layers.dense(proj_logits, 1, kernel_initializer=initializer())#, \n",
    "        #                              kernel_regularizer=regularizer)\n",
    "\n",
    "            yp = tf.sigmoid(logits)\n",
    "             # Compute predictions.\n",
    "            if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "                predictions = {\n",
    "                    'prob': yp,\n",
    "                    'logits': logits,\n",
    "                }\n",
    "\n",
    "                return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
    "\n",
    "            correct_pred = tf.equal(tf.round(yp), labels)\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "            losses = tf.nn.sigmoid_cross_entropy_with_logits(labels = labels, logits = logits)\n",
    "            loss = tf.reduce_mean(losses)\n",
    "            if hparams.l2_norm is not None:\n",
    "                    variables = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "                    l2_loss = tf.contrib.layers.apply_regularization(regularizer, variables)\n",
    "                    loss += l2_loss\n",
    "                    print(\"Adding l2\")\n",
    "        \n",
    "        metrics = {'accuracy': accuracy, \"loss\": loss}\n",
    "        if mode == tf.estimator.ModeKeys.EVAL:\n",
    "            # Compute evaluation metrics.\n",
    "            accuracy = tf.metrics.accuracy(labels=labels,\n",
    "                                           predictions=tf.round(yp),\n",
    "                                           name='eval_acc_op')\n",
    "            eval_loss = tf.metrics.mean(values=losses, name='eval_loss_op')\n",
    "            \n",
    "            metrics = {'eval_accuracy': accuracy, \n",
    "                       \"eval_loss\": eval_loss}\n",
    "            return tf.estimator.EstimatorSpec(\n",
    "                mode, loss=loss, eval_metric_ops=metrics)\n",
    "\n",
    "        # Create training op.\n",
    "        assert is_training\n",
    "\n",
    "        with tf.variable_scope(\"training\"):\n",
    "            # lr = tf.minimum(hparams.learning_rate, 0.001 / tf.log(999.) * tf.log(tf.cast(global_step, tf.float32) + 1))\n",
    "            iters_per_epoch = int(np.ceil(train_x.shape[0] / hparams.batch_size))\n",
    "            warmup_steps = 40000\n",
    "\n",
    "            global_step = tf.train.get_global_step()  # tf.Variable(0, name='global_step', trainable=False)\n",
    "#             lrate = d_model ** -0.5 * tf.minimum(tf.pow(tf.cast(global_step, tf.float32), tf.constant(-0.5)),\n",
    "#                                                  tf.constant(warmup_steps ** -1.5))\n",
    "\n",
    "            lr = tf.train.exponential_decay(\n",
    "                hparams.learning_rate, global_step, iters_per_epoch, .99, staircase=True)\n",
    "\n",
    "            optimizer = tf.train.AdamOptimizer(lr, beta1 = 0.8, beta2 = 0.999, epsilon = 1e-7)\n",
    "            # lrate = hparams.d ** -0.5 * tf.minimum(tf.pow(tf.cast(global_step, tf.float32), tf.constant(-0.5)),\n",
    "            #                                              tf.constant(3000 ** -1.5))\n",
    "            # optimizer = tf.train.AdamOptimizer(lrate, beta1=0.9, beta2=0.97, epsilon=1e-9)\n",
    "\n",
    "            params = tf.trainable_variables()\n",
    "            gradients = tf.gradients(loss, params)\n",
    "            clipped_gradients, _ = tf.clip_by_global_norm(gradients,\n",
    "                                                          hparams.max_gradient_norm)\n",
    "\n",
    "            train_op = optimizer.apply_gradients(\n",
    "                zip(clipped_gradients, params), global_step=global_step)\n",
    "\n",
    "            total_params()\n",
    "            logging_hook = tf.train.LoggingTensorHook(metrics, every_n_iter=100)\n",
    "            \n",
    "        tf.summary.scalar('cross_entropy', loss)\n",
    "        tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "        # Merge all the summaries and write them out to /tmp/mnist_logs (by default)\n",
    "        merged = tf.summary.merge_all()\n",
    "\n",
    "#        \n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op, training_hooks=[logging_hook])\n",
    "    \n",
    "    return model_fn\n",
    "\n",
    "model_fn = model_fn_builder(voc_holder, hparams, elmo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model id #1545508358\n",
      "INFO:tensorflow:Using config: {'_model_dir': './logs/model1545508358', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f24c71ebf60>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f26daa7c620>) includes params argument, but params are not passed to Estimator.\n"
     ]
    }
   ],
   "source": [
    "now = str(int(datetime.now().timestamp()))\n",
    "summaries_dir = './logs'\n",
    "# summaries_dir + '/test' + now\n",
    "\n",
    "print('Model id #{}'.format(now))\n",
    "\n",
    "\n",
    "run_config = tf.estimator.RunConfig()\n",
    "estimator = tf.estimator.Estimator(\n",
    "    model_fn=model_fn, config=run_config, model_dir=(summaries_dir + '/model' + now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 600.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "Adding l2\n"
     ]
    }
   ],
   "source": [
    "train_spec = tf.estimator.TrainSpec(lambda: input_fn(hparams.batch_size), \n",
    "                                    max_steps = 2*len(train_x)//hparams.batch_size * hparams.max_epochs)\n",
    "eval_spec = tf.estimator.EvalSpec(lambda: test_input_fn(hparams.batch_size))\n",
    "\n",
    "results = tf.estimator.train_and_evaluate(estimator, train_spec, eval_spec)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df6948453af4b4f97e90d91179b9534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4044), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_dict = pd.read_csv(\"/home/momchil/Desktop/elastic_top10_all_dict.tsv\", sep='\\t')\n",
    "\n",
    "all_dict.head()\n",
    "\n",
    "c_maxlen = hparams.decoder_length\n",
    "q_maxlen = hparams.encoder_length\n",
    "\n",
    "questions = []\n",
    "references = []\n",
    "candidates = []\n",
    "\n",
    "for idx in tqdm(range(all_dict.shape[0])):\n",
    "    \n",
    "    r = voc_holder.to_word_idx(all_dict.ix[idx, 'Reference'], -1)\n",
    "    q = voc_holder.to_word_idx(all_dict.ix[idx, 'Question'], q_maxlen)\n",
    "    candidates.append(all_dict.ix[idx, 'Hypothesis'])\n",
    "    questions.append(q)\n",
    "#     references.append(strip_punkt(r, eval_conf.voc_holder.reverse_vocab))\n",
    "    references.append(r[r.nonzero()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a4f60f3002e4890acde6dff679777fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4044), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./logs/model1545508358/model.ckpt-18382\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bc9a9f5f43444119b5d60f0144129b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU@2: 15.75774442253442\n",
      "Embedding Average: 78.22661547558036\n",
      "Greedy Matching: 31.072027783808416\n",
      "ROUGE_L: 24.61709790859387\n",
      "Vector Extrema: 40.422141354514295\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cefcd30b72c643d8a4122e47dd219e78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU@2: 15.916557220397848\n",
      "Embedding Average: 78.3932229091149\n",
      "Greedy Matching: 31.122681689190994\n",
      "ROUGE_L: 24.684578976120715\n",
      "Vector Extrema: 40.59055378862006\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b89ab883dd6d49d89ccf534fe58f7676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU@2: 15.941834567857804\n",
      "Embedding Average: 78.35599346513433\n",
      "Greedy Matching: 31.155852705404524\n",
      "ROUGE_L: 24.655845612572698\n",
      "Vector Extrema: 40.6492684395473\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c87b56a165409a90506be630c18033",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU@2: 15.78639223543167\n",
      "Embedding Average: 78.38821640725462\n",
      "Greedy Matching: 31.209832738147625\n",
      "ROUGE_L: 24.60141756206627\n",
      "Vector Extrema: 40.703585068317885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c31cbab836846e182e0dfa554672c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU@2: 15.693864391989226\n",
      "Embedding Average: 78.20456625552617\n",
      "Greedy Matching: 31.1091629957454\n",
      "ROUGE_L: 24.546035216329482\n",
      "Vector Extrema: 40.487256244664096\n",
      "Greedy\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d55e994c5f5482ab933487e0ae72dd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU@2: 15.178345469681423\n",
      "Embedding Average: 78.34437802020314\n",
      "Greedy Matching: 31.12752050195541\n",
      "ROUGE_L: 24.127489239551984\n",
      "Vector Extrema: 40.809929125897085\n"
     ]
    }
   ],
   "source": [
    "# correct solution:\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference\n",
    "\n",
    "def eval_predictions(predictions, references, is_greedy):\n",
    "    hypothesis = []\n",
    "    \n",
    "    for i, probs in enumerate(predictions):\n",
    "        try:\n",
    "            c = np.array([voc_holder.to_word_idx(c, c_maxlen) for c in candidates[i].split(\"@ @ @\")])\n",
    "            idx = probs.argmax(0)[0] if is_greedy else\\\n",
    "                  np.random.choice(range(len(probs)), 1, p=softmax(probs).T[0])[0]\n",
    "            h = c[idx]\n",
    "    #         hypothesis.append(strip_punkt(h, eval_conf.voc_holder.reverse_vocab))\n",
    "            hypothesis.append(h[h.nonzero()])\n",
    "        except:\n",
    "            print(\"Skipping\", idx)\n",
    "            raise\n",
    "\n",
    "    references = np.array(references)\n",
    "    hypothesis = np.array(hypothesis)\n",
    "    eval_conf = get_evaluation_conf(None, hparams, None, None, voc_holder)\n",
    "    evaluation = evaluate_words_index(references, hypothesis, eval_conf, hparams.evaluation_metrics, True)\n",
    "    return evaluation\n",
    "\n",
    "predictions = []\n",
    "\n",
    "eval_input_fn = eval_input_fn_builder(questions, candidates)\n",
    "pred_gen = estimator.predict(lambda: eval_input_fn(1), predict_keys='logits', yield_single_examples=False)\n",
    "for p in tqdm(pred_gen, total=len(all_dict)):\n",
    "    predictions.append(p['logits'])\n",
    "\n",
    "for _ in range(5):\n",
    "    evaluation = eval_predictions(predictions, references, False)\n",
    "    print(format_metrics(evaluation), end='\\n\\n')\n",
    "print(\"Greedy\")\n",
    "\n",
    "evaluation = eval_predictions(predictions, references, True)\n",
    "print(format_metrics(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "print(probs.T[0])\n",
    "print(softmax(probs).T[0])\n",
    "print([sigmoid(x) for x in probs.T[0]] / sum([sigmoid(x) for x in probs]))\n",
    "print([x + np.min(probs) for x in probs.T[0]] / sum([x + np.min(probs) for x in probs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### for w1, w2 in [('ipad', 'iphone'), ('hello', 'hi'), ('yes', 'no'), ('talk', 'bad'), ('love', 'hate')]:\n",
    "#     print(np.dot(bert[voc_holder.vocab[w1]], bert[voc_holder.vocab[w2]]) / \\\n",
    "#         (np.linalg.norm(bert[voc_holder.vocab[w1]]) * np.linalg.norm(bert[voc_holder.vocab[w2]])))\n",
    "#     print(np.dot(elmo[voc_holder.vocab[w1]], elmo[voc_holder.vocab[w2]]) / \\\n",
    "#         (np.linalg.norm(elmo[voc_holder.vocab[w1]]) * np.linalg.norm(elmo[voc_holder.vocab[w2]])))\n",
    "#     print()\n",
    "# # np.mean(emb_weights, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "812.85px",
    "left": "2148px",
    "right": "20px",
    "top": "120px",
    "width": "327px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
