{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library versions:\n",
      "tensorflow:1.11.0\n",
      "pandas:0.23.4\n",
      "numpy:1.15.4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5e078319e44a3993e390f4d4728bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import re\n",
    "import random\n",
    "import string\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import importlib\n",
    "\n",
    "import customersupport.common\n",
    "import customersupport.common.utils\n",
    "import customersupport.evaluation.eval\n",
    "\n",
    "print('Library versions:')\n",
    "\n",
    "import tensorflow as tf\n",
    "print('tensorflow:{}'.format(tf.__version__))\n",
    "import pandas as pd\n",
    "print('pandas:{}'.format(pd.__version__))\n",
    "# import sklearn\n",
    "# print('sklearn:{}'.format(sklearn.__version__))\n",
    "# import nltk\n",
    "# print('nltk:{}'.format(nltk.__version__))\n",
    "import numpy as np\n",
    "print('numpy:{}'.format(np.__version__))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from IPython.display import SVG\n",
    "from tqdm import tqdm_notebook as tqdm  # Special jupyter notebook progress bar\n",
    "\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "from datetime import datetime\n",
    "\n",
    "from customersupport.common.vocab import VocabHolder\n",
    "from customersupport.common.dataset import CustomerSupportDataset\n",
    "\n",
    "from customersupport.evaluation.eval import evaluate_words_index, format_metrics, get_evaluation_conf, strip_punkt\n",
    "\n",
    "importlib.reload(customersupport.common.vocab)\n",
    "importlib.reload(customersupport.common.dataset)\n",
    "importlib.reload(customersupport.common.utils)\n",
    "importlib.reload(customersupport.evaluation.eval)\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "tqdm().pandas()  # Enable tracking of progress in dataframe `apply` calls\n",
    "\n",
    "tqdm.monitor_interval = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['device: 0, name: GeForce GTX 1060 6GB, pci bus id: 0000:01:00.0, compute capability: 6.1']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.physical_device_desc for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8192 - large enough for demonstration, larger values make network training slower\n",
    "MAX_VOCAB_SIZE = 2**13\n",
    "\n",
    "# seq2seq generally relies on fixed length message vectors - longer messages provide more info\n",
    "# but result in slower training and larger networks\n",
    "#MAX_MESSAGE_LEN = 50\n",
    "\n",
    "hparams = tf.contrib.training.HParams(\n",
    "    # Larger batch sizes generally reach the average response faster, but small batch sizes are\n",
    "    # required for the model to learn nuanced responses.  Also, GPU memory limits max batch size.\n",
    "    batch_size=64,\n",
    "    encoder_length=60,\n",
    "    decoder_length=70,\n",
    "    src_vocab_size=MAX_VOCAB_SIZE,\n",
    "    # Embedding size for words - gives a trade off between expressivity of words and network size\n",
    "    embedding_size=200,\n",
    "    tgt_vocab_size=MAX_VOCAB_SIZE,\n",
    "    # Helps regularize network and prevent overfitting.\n",
    "    # High learning rate helps model reach average response faster, but can make it hard to\n",
    "    # converge on nuanced responses\n",
    "    learning_rate=5e-04,  #0.0005,\n",
    "    max_gradient_norm=5.0,\n",
    "    l2_norm = None,\n",
    "    beam_width = 10,\n",
    "    d = 128,\n",
    "    nh = 4,\n",
    "    max_epochs=15,\n",
    "    dropout=0.1,\n",
    "    use_glove=False,\n",
    "    l2_reg=0.,\n",
    "    glove_path=None,\n",
    "    #'/home/momchil/Storage/Projects/Python/Data/glove.twitter.27B/glove.twitter.27B.200d.txt',\n",
    "    tweets_path=\n",
    "    '/home/momchil/Storage/Projects/Python/Data/customer-support-on-twitter/twcs-conv_ids_clean.csv',\n",
    "    # Ngram count for ROUGE and BLEU\n",
    "    max_order = 2,\n",
    "    train_size=0.8,\n",
    "    decay_rate=0.99,\n",
    "    train_time_diff=5.0,\n",
    "    first_day=0,\n",
    "    last_day=60,\n",
    "    evaluation_metrics=[\n",
    "        \"bleu\", \"rouge_l\", \"embedding_average\", \"vector_extrema\",\n",
    "        \"greedy_matching\"\n",
    "    ],\n",
    "    training_metrics=[\n",
    "        \"bleu\", \"rouge_l\", \"embedding_average\", \"vector_extrema\",\n",
    "        \"greedy_matching\"\n",
    "    ],\n",
    "    companies=['AppleSupport'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done support_author (984679, 9)\n",
      "Replacing anonymized screen names in X...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2efdaf5f6b1b4c5fa2efeaf7ca07e67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105179), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing anonymized screen names in Y...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d3801e4e4c45ccabdaabf2fcac6934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105179), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 58.5 s, sys: 1.54 s, total: 1min\n",
      "Wall time: 54.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cs_data = CustomerSupportDataset(hparams)\n",
    "\n",
    "#& (y_text.str.contains('help') ^ True)\n",
    "#['direct message', 'is fixed in a future software update']\n",
    "cs_data.process_utterances(masks=['direct message'], append_context=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded w2v\n"
     ]
    }
   ],
   "source": [
    "voc_holder = VocabHolder(hparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CountVectorizer on X and Y text data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "628a19e588984e288550b026d8b77439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=49626), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learned vocab of 8192 items.\n",
      "Calculating word indexes for X...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fa62127ee424c309d6789284f476934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=49626), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating word indexes for Y...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a4ceed3ceb4a41b955a237ec5d5782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=49626), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data of shape (45582, 60) and test data of shape (4044, 70).\n",
      "count    45582.000000\n",
      "mean         1.000000\n",
      "std          0.141677\n",
      "min          0.740038\n",
      "25%          0.883758\n",
      "50%          1.021893\n",
      "75%          1.097074\n",
      "max          1.286219\n",
      "dtype: float64\n",
      "count    4044.000000\n",
      "mean        1.000000\n",
      "std         0.014701\n",
      "min         0.972407\n",
      "25%         0.988713\n",
      "50%         1.001299\n",
      "75%         1.011627\n",
      "max         1.022508\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "analyzer = voc_holder.fit(cs_data.x_text, cs_data.y_text, hparams.src_vocab_size)\n",
    "\n",
    "cs_data.text_to_vec(hparams, voc_holder)\n",
    "cs_data.train_test_split(hparams, do_random=False)\n",
    "\n",
    "train_x = cs_data.train_x\n",
    "train_y = cs_data.train_y\n",
    "\n",
    "test_x = cs_data.test_x\n",
    "test_y = cs_data.test_y\n",
    "\n",
    "train_weights = cs_data.train_weights\n",
    "test_weights = cs_data.test_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cs_data.x = cs_data.x_text.values\n",
    "# cs_data.y = cs_data.y_text.values\n",
    "# cs_data.train_test_split(hparams, do_random=False)\n",
    "# train_x = cs_data.train_x\n",
    "# train_y = cs_data.train_y\n",
    "\n",
    "# test_x = cs_data.test_x\n",
    "# test_y = cs_data.test_y\n",
    "\n",
    "# def export(x_sent, y_sent, path):\n",
    "#     with open(path, \"w\") as f:\n",
    "#         for x, y in tqdm(zip(x_sent, y_sent)):\n",
    "#             f.write(x + \"\\n\" + y + '\\n\\n')\n",
    "            \n",
    "# export(train_x, train_y, \"/home/momchil/Storage/Projects/Python/bert/next_sent_train.txt\")\n",
    "# export(test_x, test_y, \"/home/momchil/Storage/Projects/Python/bert/next_sent_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111ad1adeb6b4d22b6443ecac64bcca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=8192), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def export_vocab(voc_holder):\n",
    "    with open(\"/home/momchil/Storage/Projects/Python/Data/multi_cased_L-12_H-768_A-12/vocab.txt\", \"w\") as f:\n",
    "        for l in map(lambda x: voc_holder.reverse_vocab[x], range(MAX_VOCAB_SIZE)):\n",
    "            f.write(l + \"\\n\")\n",
    "\n",
    "def validate_elmo(elmo_weights, voc_holder, word):\n",
    "    elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
    "    embeddings = elmo(\n",
    "                inputs={\n",
    "                    \"tokens\": [[word]],\n",
    "                    \"sequence_len\": [1]\n",
    "                },\n",
    "                signature=\"tokens\",\n",
    "                as_dict=True)[\"elmo\"]\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        elmo_pred = sess.run(embeddings).reshape(1024)\n",
    "    embedding = elmo_weights[voc_holder.vocab[word]]\n",
    "    \n",
    "    np.testing.assert_array_almost_equal(elmo_pred, embedding, decimal=6)\n",
    "\n",
    "def export_bert(vocab_holder):\n",
    "    \n",
    "    def sum_per_layer(data, i):\n",
    "        return np.sum([t['layers'][i]['values'] for t in data['features'][1:]], 0)\n",
    "    \n",
    "    words = [\"\"] * len(voc_holder.reverse_vocab)\n",
    "    for i, w in voc_holder.reverse_vocab.items():\n",
    "        words[i] = w\n",
    "        \n",
    "    # BERT uses those 3\n",
    "    words[customersupport.common.utils.START] = '<S>'\n",
    "    words[customersupport.common.utils.PAD] = '[PAD]'\n",
    "    words[customersupport.common.utils.UNK] = '[UNK]'\n",
    "    \n",
    "    bert_weights = []\n",
    "    with open('/home/momchil/Storage/Projects/Python/Data/uncased_L-12_H-768_A-12/output.jsonl') as f:\n",
    "#         for i in range(2000): \n",
    "#             f.readline()\n",
    "        for i, w in enumerate(tqdm(words)):\n",
    "            data = json.loads(str(f.readline()))\n",
    "#             weights = np.sum([data['features'][i]['layers'][0]['values'] for i in range(len(data['features']))], 0)\n",
    "#             weights = data['features'][0]['layers'][0]['values']\n",
    "#             print( data['features'][0]['token'])\n",
    "            weights = sum_per_layer(data, 0)\n",
    "            for i in range(1, len(data['features'][0]['layers'])):\n",
    "#                 weights = np.concatenate((weights, sum_per_layer(data, i)))\n",
    "                weights += sum_per_layer(data, i)\n",
    "            bert_weights.append(weights)\n",
    "    \n",
    "    return np.array(bert_weights, dtype=np.float32)\n",
    "\n",
    "emb_weights = export_bert(voc_holder)\n",
    "emb_weights[customersupport.common.utils.PAD] = np.zeros(emb_weights.shape[-1], dtype=np.float32)\n",
    "bert = emb_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for w1, w2 in [('ipad', 'iphone'), ('hello', 'hi'), ('yes', 'no'), ('talk', 'bad'), ('love', 'hate')]:\n",
    "#     print(np.dot(bert[voc_holder.vocab[w1]], bert[voc_holder.vocab[w2]]) / \\\n",
    "#         (np.linalg.norm(bert[voc_holder.vocab[w1]]) * np.linalg.norm(bert[voc_holder.vocab[w2]])))\n",
    "#     print(np.dot(elmo[voc_holder.vocab[w1]], elmo[voc_holder.vocab[w2]]) / \\\n",
    "#         (np.linalg.norm(elmo[voc_holder.vocab[w1]]) * np.linalg.norm(elmo[voc_holder.vocab[w2]])))\n",
    "#     print()\n",
    "# # np.mean(emb_weights, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using /tmp/tfhub_modules to cache modules.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75517a1a677f4ebb8382776ebd51234b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=16), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "\n",
    "def validate_elmo(elmo_weights, voc_holder, word):\n",
    "    elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
    "    embeddings = elmo(\n",
    "                inputs={\n",
    "                    \"tokens\": [[word]],\n",
    "                    \"sequence_len\": [1]\n",
    "                },\n",
    "                signature=\"tokens\",\n",
    "                as_dict=True)[\"elmo\"]\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        elmo_pred = sess.run(embeddings).reshape(1024)\n",
    "    embedding = elmo_weights[voc_holder.vocab[word]]\n",
    "    \n",
    "    np.testing.assert_array_almost_equal(elmo_pred, embedding, decimal=6)\n",
    "\n",
    "def export_elmo(vocab_holder):\n",
    "    elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=False)\n",
    "    \n",
    "    words = [\"\"] * len(voc_holder.reverse_vocab)\n",
    "    for i, w in voc_holder.reverse_vocab.items():\n",
    "        words[i] = w\n",
    "        \n",
    "    # ELMo uses those 3\n",
    "    words[customersupport.common.utils.START] = '<S>'\n",
    "    words[customersupport.common.utils.PAD] = '</S>'\n",
    "    words[customersupport.common.utils.UNK] = '<UNK>'\n",
    "    \n",
    "    words = np.array(words, dtype=np.str).reshape(-1, 512, 1)\n",
    "\n",
    "    elmo_weights = []\n",
    "\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for tokens_input in tqdm(words):\n",
    "            embeddings = elmo(\n",
    "                inputs={\n",
    "                    \"tokens\": tokens_input,\n",
    "                    \"sequence_len\": np.ones(tokens_input.shape[0])\n",
    "                },\n",
    "                signature=\"tokens\",\n",
    "                as_dict=True)[\"elmo\"]\n",
    "            e = sess.run(embeddings)\n",
    "            elmo_weights.append(e.reshape(-1, 1024))\n",
    "\n",
    "        elmo_weights = np.array(elmo_weights).reshape(-1, 1024)\n",
    "        return elmo_weights\n",
    "\n",
    "emb_weights = export_elmo(voc_holder)\n",
    "emb_weights[customersupport.common.utils.PAD] = np.zeros(1024, dtype=np.float32)\n",
    "\n",
    "validate_elmo(emb_weights, voc_holder, \"hello\")\n",
    "elmo = emb_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.util import nest\n",
    "from tensorflow.python.ops import math_ops\n",
    "from tensorflow.python.ops import array_ops\n",
    "from tensorflow.python.ops import init_ops\n",
    "from tensorflow.python.ops import nn_ops\n",
    "from tensorflow.python.ops import clip_ops\n",
    "\n",
    "def batch_dot(x, y, axes=None):\n",
    "    \"\"\"Copy from keras==2.0.6\n",
    "    Batchwise dot product.\n",
    "    `batch_dot` is used to compute dot product of `x` and `y` when\n",
    "    `x` and `y` are data in batch, i.e. in a shape of\n",
    "    `(batch_size, :)`.\n",
    "    `batch_dot` results in a tensor or variable with less dimensions\n",
    "    than the input. If the number of dimensions is reduced to 1,\n",
    "    we use `expand_dims` to make sure that ndim is at least 2.\n",
    "    # Arguments\n",
    "        x: Keras tensor or variable with `ndim >= 2`.\n",
    "        y: Keras tensor or variable with `ndim >= 2`.\n",
    "        axes: list of (or single) int with target dimensions.\n",
    "            The lengths of `axes[0]` and `axes[1]` should be the same.\n",
    "    # Returns\n",
    "        A tensor with shape equal to the concatenation of `x`'s shape\n",
    "        (less the dimension that was summed over) and `y`'s shape\n",
    "        (less the batch dimension and the dimension that was summed over).\n",
    "        If the final rank is 1, we reshape it to `(batch_size, 1)`.\n",
    "    \"\"\"\n",
    "    if isinstance(axes, int):\n",
    "        axes = (axes, axes)\n",
    "    x_ndim = ndim(x)\n",
    "    y_ndim = ndim(y)\n",
    "    if x_ndim > y_ndim:\n",
    "        diff = x_ndim - y_ndim\n",
    "        y = tf.reshape(y, tf.concat([tf.shape(y), [1] * (diff)], axis=0))\n",
    "    elif y_ndim > x_ndim:\n",
    "        diff = y_ndim - x_ndim\n",
    "        x = tf.reshape(x, tf.concat([tf.shape(x), [1] * (diff)], axis=0))\n",
    "    else:\n",
    "        diff = 0\n",
    "    if ndim(x) == 2 and ndim(y) == 2:\n",
    "        if axes[0] == axes[1]:\n",
    "            out = tf.reduce_sum(tf.multiply(x, y), axes[0])\n",
    "        else:\n",
    "            out = tf.reduce_sum(tf.multiply(tf.transpose(x, [1, 0]), y), axes[1])\n",
    "    else:\n",
    "        if axes is not None:\n",
    "            adj_x = None if axes[0] == ndim(x) - 1 else True\n",
    "            adj_y = True if axes[1] == ndim(y) - 1 else None\n",
    "        else:\n",
    "            adj_x = None\n",
    "            adj_y = None\n",
    "        out = tf.matmul(x, y, adjoint_a=adj_x, adjoint_b=adj_y)\n",
    "    if diff:\n",
    "        if x_ndim > y_ndim:\n",
    "            idx = x_ndim + y_ndim - 3\n",
    "        else:\n",
    "            idx = x_ndim - 1\n",
    "        out = tf.squeeze(out, list(range(idx, idx + diff)))\n",
    "    if ndim(out) == 1:\n",
    "        out = tf.expand_dims(out, 1)\n",
    "    return out\n",
    "\n",
    "def ndim(x):\n",
    "    \"\"\"Copied from keras==2.0.6\n",
    "    Returns the number of axes in a tensor, as an integer.\n",
    "    # Arguments\n",
    "        x: Tensor or variable.\n",
    "    # Returns\n",
    "        Integer (scalar), number of axes.\n",
    "    # Examples\n",
    "    ```python\n",
    "        >>> from keras import backend as K\n",
    "        >>> inputs = K.placeholder(shape=(2, 4, 5))\n",
    "        >>> val = np.array([[1, 2], [3, 4]])\n",
    "        >>> kvar = K.variable(value=val)\n",
    "        >>> K.ndim(inputs)\n",
    "        3\n",
    "        >>> K.ndim(kvar)\n",
    "        2\n",
    "    ```\n",
    "    \"\"\"\n",
    "    dims = x.get_shape()._dims\n",
    "    if dims is not None:\n",
    "        return len(dims)\n",
    "    return None\n",
    "\n",
    "def dot(x, y):\n",
    "    \"\"\"Modified from keras==2.0.6\n",
    "    Multiplies 2 tensors (and/or variables) and returns a *tensor*.\n",
    "    When attempting to multiply a nD tensor\n",
    "    with a nD tensor, it reproduces the Theano behavior.\n",
    "    (e.g. `(2, 3) * (4, 3, 5) -> (2, 4, 5)`)\n",
    "    # Arguments\n",
    "        x: Tensor or variable.\n",
    "        y: Tensor or variable.\n",
    "    # Returns\n",
    "        A tensor, dot product of `x` and `y`.\n",
    "    \"\"\"\n",
    "    if ndim(x) is not None and (ndim(x) > 2 or ndim(y) > 2):\n",
    "        x_shape = []\n",
    "        for i, s in zip(x.get_shape().as_list(), tf.unstack(tf.shape(x))):\n",
    "            if i is not None:\n",
    "                x_shape.append(i)\n",
    "            else:\n",
    "                x_shape.append(s)\n",
    "        x_shape = tuple(x_shape)\n",
    "        y_shape = []\n",
    "        for i, s in zip(y.get_shape().as_list(), tf.unstack(tf.shape(y))):\n",
    "            if i is not None:\n",
    "                y_shape.append(i)\n",
    "            else:\n",
    "                y_shape.append(s)\n",
    "        y_shape = tuple(y_shape)\n",
    "        y_permute_dim = list(range(ndim(y)))\n",
    "        y_permute_dim = [y_permute_dim.pop(-2)] + y_permute_dim\n",
    "        xt = tf.reshape(x, [-1, x_shape[-1]])\n",
    "        yt = tf.reshape(tf.transpose(y, perm=y_permute_dim), [y_shape[-2], -1])\n",
    "        return tf.reshape(tf.matmul(xt, yt),\n",
    "                          x_shape[:-1] + y_shape[:-2] + y_shape[-1:])\n",
    "    if isinstance(x, tf.SparseTensor):\n",
    "        out = tf.sparse_tensor_dense_matmul(x, y)\n",
    "    else:\n",
    "        out = tf.matmul(x, y)\n",
    "    return out\n",
    "    \n",
    "initializer = lambda: tf.contrib.layers.variance_scaling_initializer(factor=1.0,\n",
    "                                                             mode='FAN_AVG',\n",
    "                                                             uniform=True,\n",
    "                                                             dtype=tf.float32)\n",
    "initializer_relu = lambda: tf.contrib.layers.variance_scaling_initializer(factor=2.0,\n",
    "                                                             mode='FAN_IN',\n",
    "                                                             uniform=False,\n",
    "                                                             dtype=tf.float32)\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale = 3e-7)\n",
    "\n",
    "def optimized_trilinear_for_attention(args, c_maxlen, q_maxlen, input_keep_prob=1.0,\n",
    "    scope='efficient_trilinear',\n",
    "    bias_initializer=tf.zeros_initializer(),\n",
    "    kernel_initializer=initializer()):\n",
    "    assert len(args) == 2, \"just use for computing attention with two input\"\n",
    "    arg0_shape = args[0].get_shape().as_list()\n",
    "    arg1_shape = args[1].get_shape().as_list()\n",
    "    if len(arg0_shape) != 3 or len(arg1_shape) != 3:\n",
    "        raise ValueError(\"`args` must be 3 dims (batch_size, len, dimension)\")\n",
    "    if arg0_shape[2] != arg1_shape[2]:\n",
    "        raise ValueError(\"the last dimension of `args` must equal\")\n",
    "    arg_size = arg0_shape[2]\n",
    "    dtype = args[0].dtype\n",
    "    droped_args = [tf.nn.dropout(arg, input_keep_prob) for arg in args]\n",
    "    with tf.variable_scope(scope):\n",
    "        weights4arg0 = tf.get_variable(\n",
    "            \"linear_kernel4arg0\", [arg_size, 1],\n",
    "            dtype=dtype,\n",
    "            regularizer=regularizer,\n",
    "            initializer=kernel_initializer)\n",
    "        weights4arg1 = tf.get_variable(\n",
    "            \"linear_kernel4arg1\", [arg_size, 1],\n",
    "            dtype=dtype,\n",
    "            regularizer=regularizer,\n",
    "            initializer=kernel_initializer)\n",
    "        weights4mlu = tf.get_variable(\n",
    "            \"linear_kernel4mul\", [1, 1, arg_size],\n",
    "            dtype=dtype,\n",
    "            regularizer=regularizer,\n",
    "            initializer=kernel_initializer)\n",
    "        biases = tf.get_variable(\n",
    "            \"linear_bias\", [1],\n",
    "            dtype=dtype,\n",
    "            regularizer=regularizer,\n",
    "            initializer=bias_initializer)\n",
    "        subres0 = tf.tile(dot(droped_args[0], weights4arg0), [1, 1, q_maxlen])\n",
    "        subres1 = tf.tile(tf.transpose(dot(droped_args[1], weights4arg1), perm=(0, 2, 1)), [1, c_maxlen, 1])\n",
    "        subres2 = batch_dot(droped_args[0] * weights4mlu, tf.transpose(droped_args[1], perm=(0, 2, 1)))\n",
    "        res = subres0 + subres1 + subres2\n",
    "        tf.nn.bias_add(res, tf.tile(biases, [q_maxlen]))\n",
    "        \n",
    "    return res\n",
    "\n",
    "def context2query(c: tf.Tensor, q: tf.Tensor, mask_c: tf.Tensor, mask_q: tf.Tensor, input_keep_prob: float):\n",
    "    with tf.variable_scope(\"Context_to_Query_Attention_Layer\"):\n",
    "        S = optimized_trilinear_for_attention([c, q], tf.shape(c)[1], tf.shape(q)[1], input_keep_prob)\n",
    "        S = mask_matrix(mask_q, S, tf.shape(c)[1])\n",
    "\n",
    "        S_ = tf.nn.softmax(S)\n",
    "        S_ *= tf.tile(tf.expand_dims(mask_c, -1), [1, 1, tf.shape(q)[1]]) \n",
    "        S_T = tf.transpose(tf.nn.softmax(S, axis = 1),(0,2,1))\n",
    "        \n",
    "        c2q = tf.matmul(S_, q)\n",
    "        q2c = tf.matmul(tf.matmul(S_, S_T), c)\n",
    "        attention_outputs = [c, c2q, c * c2q, c * q2c, S_]\n",
    "        \n",
    "        return attention_outputs\n",
    "    \n",
    "def linear(context: tf.Tensor, c_maxlen):\n",
    "    with tf.variable_scope(\"Linear\"):\n",
    "        wl = tf.get_variable(\"Wl\", shape=[1, c_maxlen], \n",
    "                             initializer=tf.contrib.layers.xavier_initializer())\n",
    "        out = tf.matmul(tf.tile(tf.expand_dims(wl, 0), [tf.shape(context)[0], 1, 1]), context)\n",
    "        \n",
    "        return tf.squeeze(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_tensor(inputs, pretrained_embs, name, trainable=False):\n",
    "\n",
    "    train_embeddings = tf.get_variable(\n",
    "        name=name,\n",
    "        shape=[hparams.tgt_vocab_size - len(voc_holder.glove_weights), hparams.embedding_size],\n",
    "        initializer=tf.random_uniform_initializer(-0.04, 0.04),\n",
    "        trainable=True)\n",
    "    \n",
    "    embeddings = tf.concat(\n",
    "        [train_embeddings, pretrained_embs], axis=0)\n",
    "\n",
    "    return tf.nn.embedding_lookup(embeddings, inputs), embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7999999999999998"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "def cosine_similarity(v1,v2, use_elmo=True):\n",
    "    if (use_elmo):\n",
    "        v1 = np.array(list(map(lambda idx: elmo_weights[idx], filter(lambda idx: idx != 0, v1))))\n",
    "        v1 = np.mean(v1, 0)\n",
    "\n",
    "        v2 = np.array(list(map(lambda idx: elmo_weights[idx], filter(lambda idx: idx != 0, v2))))\n",
    "        v2 = np.mean(v2, 0)\n",
    "    else:\n",
    "        mx = hparams.src_vocab_size # max(np.max(v1), np.max(v2)) + 1\n",
    "        v1_tmp = np.zeros(mx)\n",
    "        v1_tmp[v1] = 1.\n",
    "        v1 = v1_tmp\n",
    "        \n",
    "        v2_tmp = np.zeros(mx)\n",
    "        v2_tmp[v2] = 1.\n",
    "        v2 = v2_tmp\n",
    "        \n",
    "    return np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2))      \n",
    "#     return -np.linalg.norm(v1-v2)\n",
    "\n",
    "def next_batch(train_x, train_y, batch_size, is_train = False, negatives = True):\n",
    "    feed_dict = {}\n",
    "    feed_dict[p] = []\n",
    "    feed_dict[ctx] = []\n",
    "    feed_dict[qry] = []\n",
    "    feed_dict[dropout] = 0.0 if not is_train else hparams.dropout\n",
    "    \n",
    "    ids = np.random.choice(range(len(train_x)), size=batch_size, replace=False)\n",
    "    np.random.shuffle(ids)\n",
    "    ids_targets = np.random.choice(range(len(train_x)), size=batch_size, replace=False)\n",
    "    np.random.shuffle(ids_targets)\n",
    "    \n",
    "    for i, it in zip(ids, ids_targets):\n",
    "        feed_dict[p].append([1.])\n",
    "        feed_dict[ctx].append(train_y[i])\n",
    "        feed_dict[qry].append(train_x[i])\n",
    "        \n",
    "        if (len(feed_dict[p]) == batch_size):\n",
    "            break\n",
    "        \n",
    "        if (not negatives):\n",
    "            continue\n",
    "        \n",
    "        sim = cosine_similarity(train_y[i], train_y[it], False)\n",
    "#         print(sim)\n",
    "        feed_dict[p].append([float(sim > .7)])\n",
    "#         feed_dict[p].append([0.])\n",
    "        feed_dict[ctx].append(train_y[it])\n",
    "        feed_dict[qry].append(train_x[i])\n",
    "        \n",
    "        if (len(feed_dict[p]) == batch_size):\n",
    "            break\n",
    "    \n",
    "    return feed_dict\n",
    "# def next_batch(train_x, train_y, batch_size):\n",
    "#     feed_dict = {}\n",
    "    \n",
    "#     ids = np.random.choice(range(len(train_x)), size=3 * batch_size, replace=False) \n",
    "#     ids = ids.reshape(3, batch_size)\n",
    "#     target_ids = []\n",
    "       \n",
    "    \n",
    "\n",
    "#     for i in range(3):\n",
    "#         feed_dict[inputs[i]] = train_y[ids[i]]\n",
    "\n",
    "#     for i in range(batch_size):\n",
    "#         idx = np.random.randint(0, 3, 1)[0]\n",
    "#         target_ids.append(ids[idx][i])\n",
    "        \n",
    "#     ys = train_y[target_ids]\n",
    "#     feed_dict[inputs[3]] = train_x[target_ids, :-10]\n",
    "        \n",
    "#     ysc = [[cosine_similarity(ys[i], feed_dict[inputs[0]][i]), \n",
    "#         cosine_similarity(ys[i], feed_dict[inputs[1]][i]), \n",
    "#         cosine_similarity(ys[i], feed_dict[inputs[2]][i])] for i in range(batch_size)]\n",
    "    \n",
    "# #     ysc = [np.exp(x - np.max(x)) /  np.exp(x - np.max(x)).sum(axis=0) for x in ysc]\n",
    "\n",
    "#     feed_dict[o_probs] = ysc\n",
    "    \n",
    "#     return feed_dict\n",
    "\n",
    "cosine_similarity([5, 10, 1, 4, 3], [0, 5, 10, 3, 4], False)\n",
    "# next_batch(train_x, train_y, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parametric_relu(_x):\n",
    "    alphas = tf.get_variable('alpha', _x.get_shape()[-1],\n",
    "                       initializer=initializer_relu(),\n",
    "                        dtype=tf.float32)\n",
    "    pos = tf.nn.relu(_x)\n",
    "    neg = alphas * (_x - abs(_x)) * 0.5\n",
    "\n",
    "    return pos + neg\n",
    "\n",
    "def gelu_fast(_x):\n",
    "    return 0.5 * _x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (_x + 0.044715 * tf.pow(_x, 3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of trainable parameters: 1241161\n"
     ]
    }
   ],
   "source": [
    "from QANet.layers import residual_block, highway, conv, mask_logits, trilinear, \\\n",
    "total_params#, optimized_trilinear_for_attention\n",
    "\n",
    "c_maxlen = hparams.decoder_length\n",
    "q_maxlen = hparams.encoder_length\n",
    "\n",
    "tf.reset_default_graph()\n",
    "dropout = tf.placeholder_with_default(0.0, (), name=\"dropout\")\n",
    "\n",
    "p = tf.placeholder(dtype=tf.float32, shape=(None, 1), name=\"prob\")\n",
    "\n",
    "qry = tf.placeholder(dtype=tf.int32, shape=(None, q_maxlen), name=\"query\")\n",
    "ctx = tf.placeholder(dtype=tf.int32, shape=(None, c_maxlen), name=\"elastic\")\n",
    "\n",
    "c_mask = tf.cast(ctx, tf.bool)\n",
    "q_mask = tf.cast(qry, tf.bool)\n",
    "\n",
    "c_len = tf.reduce_sum(tf.cast(c_mask, tf.int32), axis=1)\n",
    "q_len = tf.reduce_sum(tf.cast(q_mask, tf.int32), axis=1)\n",
    "\n",
    "with tf.variable_scope(\"Input_Embedding_Layer\"):\n",
    "#     pretrained_embs = tf.get_variable(\n",
    "#         name=\"embs_pretrained\",\n",
    "#         initializer=tf.constant_initializer(\n",
    "#            voc_holder.glove_weights, dtype=tf.float32),\n",
    "#         shape=voc_holder.glove_weights.shape,\n",
    "#         trainable=False)\n",
    "\n",
    "    emb_tensor = tf.convert_to_tensor(emb_weights)\n",
    "#     c_emb, _  = embed_tensor(ctx, pretrained_embs, \"embedding_ctx_glove\")\n",
    "#     q_emb, _  = embed_tensor(qry, pretrained_embs, \"embedding_qry_glove\")\n",
    "\n",
    "#     c_emb = tf.nn.dropout(c_emb, 1.0 - dropout) \n",
    "#     q_emb = tf.nn.dropout(q_emb, 1.0 - dropout) \n",
    "    c_emb_ = tf.nn.dropout(tf.nn.embedding_lookup(emb_tensor, ctx), 1.0 - dropout)\n",
    "    q_emb_ = tf.nn.dropout(tf.nn.embedding_lookup(emb_tensor, qry), 1.0 - dropout)\n",
    "\n",
    "    c_emb = highway(c_emb_, size = hparams.d, scope = \"highway\", dropout = dropout, reuse = None)\n",
    "    q_emb = highway(q_emb_, size = hparams.d, scope = \"highway\", dropout = dropout, reuse = True)\n",
    "    \n",
    "with tf.variable_scope(\"Embedding_Encoder_Layer\"):\n",
    "    c = residual_block(inputs=c_emb,\n",
    "        num_blocks = 1,\n",
    "        num_conv_layers = 4,\n",
    "        kernel_size = 7,\n",
    "        mask = c_mask,\n",
    "        num_filters = hparams.d,\n",
    "        num_heads = hparams.nh,\n",
    "        seq_len = c_len,\n",
    "        scope = \"Encoder_Residual_Block\",\n",
    "        bias = False,\n",
    "        dropout = dropout)\n",
    "    \n",
    "    q = residual_block(inputs=q_emb,\n",
    "        num_blocks = 1,\n",
    "        num_conv_layers = 4,\n",
    "        kernel_size = 7,\n",
    "        mask = q_mask,\n",
    "        num_filters = hparams.d,\n",
    "        num_heads = hparams.nh,\n",
    "        seq_len = q_len,\n",
    "        scope = \"Encoder_Residual_Block\",\n",
    "        reuse = True, # Share the weights between passage and question\n",
    "        bias = False,\n",
    "        dropout = dropout)\n",
    "    \n",
    "with tf.variable_scope(\"Context_to_Query_Attention_Layer\"):\n",
    "#     C = tf.tile(tf.expand_dims(c,2),[1,1,q_maxlen,1])\n",
    "#     Q = tf.tile(tf.expand_dims(q,1),[1,c_maxlen,1,1])\n",
    "#     S = trilinear([C, Q, C*Q], input_keep_prob = 1.0 - dropout)\n",
    "    S = optimized_trilinear_for_attention([c, q], c_maxlen, q_maxlen, input_keep_prob = 1.0 - dropout)\n",
    "    mask_q = tf.expand_dims(q_mask, 1)\n",
    "    S_ = tf.nn.softmax(mask_logits(S, mask = mask_q))\n",
    "    mask_c = tf.expand_dims(c_mask, 2)\n",
    "    S_T = tf.transpose(tf.nn.softmax(mask_logits(S, mask = mask_c), axis = 1),(0,2,1))\n",
    "    c2q = tf.matmul(S_, q)\n",
    "    q2c = tf.matmul(tf.matmul(S_, S_T), c)\n",
    "    attention_outputs = [c, c2q, c * c2q, c * q2c]\n",
    "\n",
    "with tf.variable_scope(\"Model_Encoder_Layer\"):\n",
    "    inputs = tf.concat(attention_outputs, axis = -1)\n",
    "    enc = [conv(inputs, hparams.d, name = \"input_projection\")]\n",
    "    for i in range(2):\n",
    "        if i % 2 == 0: # dropout every 2 blocks\n",
    "            enc[i] = tf.nn.dropout(enc[i], 1.0 - dropout)\n",
    "        enc.append(\n",
    "            residual_block(enc[i],\n",
    "                num_blocks = 7,\n",
    "                num_conv_layers = 2,\n",
    "                kernel_size = 5,\n",
    "                mask = c_mask,\n",
    "                num_filters = hparams.d,\n",
    "                num_heads = hparams.nh,\n",
    "                seq_len = c_len,\n",
    "                scope = \"Model_Encoder\",\n",
    "                bias = False,\n",
    "                reuse = True if i > 0 else None,\n",
    "                dropout = dropout)\n",
    "            )\n",
    "with tf.variable_scope(\"Output_Layer\"):\n",
    "#     proj_logits = tf.squeeze(conv(tf.concat([enc[1], enc[2]],axis = -1),1, bias = False, name = \"first_logits\"),-1)\n",
    "    proj_logits = tf.squeeze(conv(enc[1], 1, bias = False, name = \"first_logits\"), -1)\n",
    "    proj_logits = tf.concat([proj_logits, \n",
    "                             batch_dot(tf.reduce_max(tf.abs(q_emb), 1), tf.reduce_max(tf.abs(c_emb), 1), 1),\n",
    "                             tf.reduce_sum(q_emb_, 1),\n",
    "                             tf.reduce_sum(c_emb_, 1)\n",
    "#                              tf.reduce_max(c_emb, 1),\n",
    "#                              tf.reduce_max(q_emb, 1),\n",
    "#                              tf.reduce_min(c_emb, 1),\n",
    "#                              tf.reduce_min(q_emb, 1),\n",
    "#                              tf.reshape(tf.reduce_sum(tf.to_float(tf.equal(ctx, 1)), 1), (-1, 1)),\n",
    "#                              tf.reshape(tf.reduce_sum(tf.to_float(tf.equal(qry, 1)), 1), (-1, 1)),\n",
    "#                              tf.reduce_max(tf.one_hot(ctx, MAX_VOCAB_SIZE, on_value=1.0, off_value=0.0, axis =-1), 1),\n",
    "#                              tf.reduce_max(tf.one_hot(qry, MAX_VOCAB_SIZE, on_value=1.0, off_value=0.0, axis =-1), 1)\n",
    "                            ], 1)\n",
    "    \n",
    "    proj_logits = tf.nn.dropout(proj_logits, 1.0 - dropout)\n",
    "#     second_logits = tf.squeeze(conv(tf.concat([enc[1], enc[3]],axis = -1),1,\n",
    "# bias = False, name = \"second_logits\"),-1)\n",
    "#     third_logits = tf.squeeze(conv(tf.concat([enc[2], enc[3]],axis = -1),1, \n",
    "# bias = False, name = \"third_logits\"),-1)\n",
    "#     proj_logits = tf.squeeze(conv(enc[1] ,1, bias = False, name = \"first_logits\"), -1)\n",
    "    \n",
    "#     proj_logits = tf.layers.dense(proj_logits, 512, kernel_initializer=initializer(), \n",
    "#                                   activation=gelu_fast, kernel_regularizer=regularizer)\n",
    "#     proj_logits = tf.nn.dropout(proj_logits, 1.0 - dropout)\n",
    "    \n",
    "#     proj_logits = tf.layers.dense(proj_logits, 256, kernel_initializer=initializer(), \n",
    "#                                   activation=parametric_relu, kernel_regularizer=regularizer)\n",
    "#     proj_logits = tf.nn.dropout(proj_logits, 1.0 - dropout)\n",
    "    \n",
    "#     proj_logits = tf.layers.dense(proj_logits, 128, kernel_initializer=initializer(), \n",
    "#                                   activation=parametric_relu, kernel_regularizer=regularizer)\n",
    "#     proj_logits = tf.layers.dense(proj_logits, hparams.d // 2, kernel_initializer=initializer(), \n",
    "#                                   activation=parametric_relu)\n",
    "\n",
    "#     proj_logits = tf.squeeze(conv(proj_logits, 1, bias = False, name = \"proj_logits\"), -1)\n",
    "    \n",
    "    logits = tf.layers.dense(proj_logits, 1, kernel_initializer=initializer())#, \n",
    "#                              kernel_regularizer=regularizer)\n",
    "    yp = tf.sigmoid(logits)\n",
    "    correct_pred = tf.equal(tf.round(yp), p)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "    \n",
    "    losses = tf.nn.sigmoid_cross_entropy_with_logits(labels = p, logits = logits)\n",
    "    loss = tf.reduce_mean(losses)\n",
    "    \n",
    "if hparams.l2_norm is not None:\n",
    "    variables = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "    l2_loss = tf.contrib.layers.apply_regularization(regularizer, variables)\n",
    "    loss += l2_loss\n",
    "    print(\"Adding l2\")\n",
    "    \n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "# lr = tf.minimum(hparams.learning_rate, 0.001 / tf.log(999.) * tf.log(tf.cast(global_step, tf.float32) + 1))\n",
    "iters_per_epoch = int(np.ceil(train_x.shape[0] / hparams.batch_size))\n",
    "\n",
    "# Optimization\n",
    "lr = tf.train.exponential_decay(\n",
    "    hparams.learning_rate, global_step, iters_per_epoch, .99, staircase=True)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(lr, beta1 = 0.8, beta2 = 0.999, epsilon = 1e-7)\n",
    "# lrate = hparams.d ** -0.5 * tf.minimum(tf.pow(tf.cast(global_step, tf.float32), tf.constant(-0.5)),\n",
    "#                                              tf.constant(3000 ** -1.5))\n",
    "# optimizer = tf.train.AdamOptimizer(lrate, beta1=0.9, beta2=0.97, epsilon=1e-9)\n",
    "\n",
    "params = tf.trainable_variables()\n",
    "gradients = tf.gradients(loss, params)\n",
    "clipped_gradients, _ = tf.clip_by_global_norm(gradients,\n",
    "                                              hparams.max_gradient_norm)\n",
    "\n",
    "train_op = optimizer.apply_gradients(\n",
    "    zip(clipped_gradients, params), global_step=global_step)\n",
    "\n",
    "total_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model id #1545087828\n"
     ]
    }
   ],
   "source": [
    "tf.summary.scalar('cross_entropy', loss)\n",
    "tf.summary.scalar('accuracy', accuracy)\n",
    "\n",
    "# Merge all the summaries and write them out to /tmp/mnist_logs (by default)\n",
    "merged = tf.summary.merge_all()\n",
    "now = str(int(datetime.now().timestamp()))\n",
    "summaries_dir = './logs'\n",
    "train_writer = tf.summary.FileWriter(summaries_dir + '/train' + now,\n",
    "                                      sess.graph)\n",
    "test_writer = tf.summary.FileWriter(summaries_dir + '/test' + now)\n",
    "print('Model id #{}'.format(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting epoch = 1/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5bdf7076e148e2a729514fa5180669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=712), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.307510025045845\n",
      "\n",
      "Train elapsed 147.24563431739807, Test elapsed 2.0265579223632812e-05\n",
      "Updating lr = 0.0005000000237487257\n",
      "\n",
      "Starting epoch = 2/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cef10b45b00444398df209697f955c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=712), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8366588379643606\n",
      "\n",
      "Train elapsed 131.7603759765625, Test elapsed 2.0742416381835938e-05\n",
      "Updating lr = 0.0004949999856762588\n",
      "\n",
      "Starting epoch = 3/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fc78a285b0040c2927089dce68c5d88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=712), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.701325458254707\n",
      "\n",
      "Train elapsed 132.4077877998352, Test elapsed 8.749961853027344e-05\n",
      "Updating lr = 0.0004900500061921775\n",
      "\n",
      "Starting epoch = 4/15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b146304e258648e392ec3d245e0d1981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=712), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train\n",
    "try:\n",
    "    for epoch in range(hparams.max_epochs):\n",
    "        print('\\nStarting epoch = {}/{}'.format(epoch + 1, hparams.max_epochs))\n",
    "\n",
    "        losss = 0.0\n",
    "        last_test_loss = float('Inf')\n",
    "        perc = 0\n",
    "        t_start = time.time()\n",
    "        \n",
    "        iters_per_epoch = len(train_x) // hparams.batch_size\n",
    "        for i in tqdm(range(iters_per_epoch)):\n",
    "            try:\n",
    "                step = sess.run(global_step)\n",
    "                feed_dict = next_batch(train_x, train_y, hparams.batch_size, True)\n",
    "                \n",
    "                _, loss_value, summary = sess.run([train_op, loss, merged], feed_dict=feed_dict)\n",
    "                losss += loss_value\n",
    "                train_writer.add_summary(summary, step)\n",
    "\n",
    "                if (i % 10 == 0):\n",
    "                    feed_dict = next_batch(test_x, test_y, hparams.batch_size, False)\n",
    "                    summary = sess.run(merged, feed_dict=feed_dict)\n",
    "                    test_writer.add_summary(summary, step)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                print(feed_dict)\n",
    "\n",
    "        t_epoch_end = time.time() - t_start\n",
    "\n",
    "        t_start = time.time()\n",
    "        \n",
    "        print(losss / iters_per_epoch)\n",
    "        \n",
    "        t_test_end = time.time() - t_start\n",
    "        \n",
    "#         print(format_metrics(evaluation))\n",
    "        print()\n",
    "        print('Train elapsed {}, Test elapsed {}'.format(t_epoch_end, t_test_end))\n",
    "        print('Updating lr = {}'.format(sess.run(lr)))\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\nHalting training from keyboard interrupt.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = next_batch(train_x, train_y, 1, negatives=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2b16a8878062>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffc762e7c4864699a61db2dd240aff8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4044), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU@2: 14.489494496198416\n",
      "Embedding Average: 76.77852005419523\n",
      "Greedy Matching: 29.799201824978688\n",
      "ROUGE_L: 21.28191459864267\n",
      "Vector Extrema: 38.87155947091704\n"
     ]
    }
   ],
   "source": [
    "all_dict = pd.read_csv(\"/home/momchil/Desktop/elastic_top10_all_dict.tsv\", sep='\\t')\n",
    "\n",
    "all_dict.head()\n",
    "references = []\n",
    "hypothesis = []\n",
    "\n",
    "# correct solution:\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum(axis=0) # only difference\n",
    "\n",
    "def predict(question, candidates, sess, model):\n",
    "    feed_dict = {}\n",
    "    feed_dict[dropout] = 0.0\n",
    "    feed_dict[ctx] = [c for c in candidates]\n",
    "    feed_dict[qry] = [question] * len(candidates)\n",
    "    \n",
    "    probs = sess.run(model, feed_dict)\n",
    "    \n",
    "    return probs\n",
    "\n",
    "for idx in tqdm(range(all_dict.shape[0])):\n",
    "    try:\n",
    "#         h, r, i = predict_pandas(all_dict, idx, do_predict=True)\n",
    "#         h, r,i  = predict_pandas(all_dict, idx, do_predict=False)\n",
    "\n",
    "        r = voc_holder.to_word_idx(all_dict.ix[idx, 'Reference'], -1)\n",
    "\n",
    "        c = [voc_holder.to_word_idx(c, c_maxlen) for c in all_dict.ix[idx, 'Hypothesis'].split(\"@ @ @\")]\n",
    "        c = np.unique(c, axis=0)\n",
    "        q = voc_holder.to_word_idx(all_dict.ix[idx, 'Question'], q_maxlen)\n",
    "        \n",
    "        probs =predict(q[0:q_maxlen], c, sess, logits)\n",
    "#         h = c[np.argmax(probs)]\n",
    "        h = c[np.random.choice(range(len(probs)), 1, p=softmax(probs).T[0])[0]]\n",
    "\n",
    "#         references.append(strip_punkt(r, eval_conf.voc_holder.reverse_vocab))\n",
    "#         hypothesis.append(strip_punkt(h, eval_conf.voc_holder.reverse_vocab))\n",
    "        references.append(r[r.nonzero()])\n",
    "        hypothesis.append(h[h.nonzero()])\n",
    "    except:\n",
    "        print(\"Skipping\", idx)\n",
    "        \n",
    "references = np.array(references)\n",
    "hypothesis = np.array(hypothesis)\n",
    "eval_conf = get_evaluation_conf(None, hparams, None, None, voc_holder)\n",
    "evaluation = evaluate_words_index(references, hypothesis, eval_conf, hparams.evaluation_metrics, True)\n",
    "print(format_metrics(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saver.restore(sess, \"./models/1544353641/model.ckpt\")\n",
    "# saver.restore(sess, \"./models/1544624781/model.ckpt\")\n",
    "# print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_conf = get_evaluation_conf(None, hparams, None, None, voc_holder)\n",
    "evaluation = evaluate_words_index(references, hypothesis, eval_conf, hparams.evaluation_metrics, True)\n",
    "print(format_metrics(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_errors(x, y):\n",
    "    i = 0\n",
    "    pbar = tqdm(total=x.shape[0] // hparams.batch_size)\n",
    "\n",
    "    q = []\n",
    "    c = []\n",
    "    p = []\n",
    "    l = []\n",
    "    \n",
    "    while i < x.shape[0]:\n",
    "        fd = (next_batch(x[i:(i+hparams.batch_size)], \n",
    "                                              y[i:(i+hparams.batch_size)], \n",
    "                                              len(y[i:(i+hparams.batch_size)]), False))\n",
    "        \n",
    "        pp, pl = sess.run([yp, losses], feed_dict=fd)\n",
    "        \n",
    "        for j in range(len(pp)):\n",
    "            q.append(voc_holder.from_word_idx(fd[qry][j]))\n",
    "            c.append(voc_holder.from_word_idx(fd[ctx][j]))\n",
    "            p.append(pp[j])\n",
    "            l.append(pl[j])\n",
    "        i += hparams.batch_size\n",
    "        pbar.update(1)\n",
    "        \n",
    "    df = pd.DataFrame(data = np.stack((q, c, np.array(p).reshape(-1), np.array(l).reshape(-1)), axis=1), \n",
    "                 columns = [\"Question\", \"Context\", \"Probability\", \"Loss\" ])\n",
    "        \n",
    "    df.to_csv('/home/momchil/Desktop/errors_test_all_dict.tsv', sep='\\t', encoding='utf-8')\n",
    "        \n",
    "export_errors(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = saver.save(sess, \"./models/1544624781/model.ckpt\")\n",
    "print(\"Model saved in path: %s\" % save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = next_batch(train_x, train_y, 2)\n",
    "print(feed_dict[p])\n",
    "print()\n",
    "print(voc_holder.from_word_idx(feed_dict[qry][0]))\n",
    "print(voc_holder.from_word_idx(feed_dict[ctx][0]))\n",
    "\n",
    "print()\n",
    "print(voc_holder.from_word_idx(feed_dict[qry][1]))\n",
    "print(voc_holder.from_word_idx(feed_dict[ctx][1]))\n",
    "\n",
    "sess.run(yp, feed_dict)\n",
    "# sess.run(tf.nn.embedding_lookup(elmo_tensor, ctx), feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(question, candidates, sess, model):\n",
    "    feed_dict = {}\n",
    "    feed_dict[dropout] = 0.0\n",
    "    feed_dict[ctx] = [c for c in candidates]\n",
    "    feed_dict[qry] = [question] * len(candidates)\n",
    "    \n",
    "    probs = sess.run(model, feed_dict)\n",
    "    \n",
    "    return probs\n",
    "\n",
    "def predict_pandas(df, idx, do_predict = True, i = None):\n",
    "    row = df.iloc[idx]\n",
    "    \n",
    "    cols = list(filter(lambda c: \"Hypothesis\" in c, all_dict.columns.tolist()))\n",
    "    c_raw = row[cols]\n",
    "    candidates = [voc_holder.to_word_idx(x, c_maxlen) for x in c_raw]\n",
    "    \n",
    "    question = voc_holder.to_word_idx(row['Question'], q_maxlen)\n",
    "    if do_predict:\n",
    "        probs = predict(question, candidates, sess, yp)\n",
    "        i = np.random.choice(range(len(candidates)), size=1, p=probs.T[0]/probs.sum())[0]\n",
    "    else:\n",
    "        i = i if i is not None else np.random.randint(0, 3)\n",
    "    \n",
    "    ref = voc_holder.to_word_idx(row['Reference'], -1)\n",
    "    hyp =  voc_holder.to_word_idx(c_raw[i], -1)\n",
    "    return hyp, ref, i\n",
    "\n",
    "\n",
    "def trimAllColumns(df):\n",
    "    \"\"\"\n",
    "    Trim whitespace from ends of each value across all series in dataframe\n",
    "    \"\"\"\n",
    "    trimStrings = lambda x: x.strip() if type(x) is str else x\n",
    "    return df.applymap(trimStrings)\n",
    "\n",
    "trans_all_dict = pd.read_csv(\"data/transformer_all_dict.tsv\", sep='\\t')[['Question', 'Reference', 'Hypothesis']]\n",
    "es_all_dict = pd.read_csv(\"data/elastic_all_dict.tsv\", sep='\\t')[['Question', 'Reference', 'Hypothesis']]\n",
    "s2s_all_dict = pd.read_csv(\"data/seq2seq_all_dict.tsv\", sep='\\t')[['Question', 'Reference', 'Hypothesis']]\n",
    "\n",
    "es_all_dict = trimAllColumns(es_all_dict)\n",
    "trans_all_dict = trimAllColumns(trans_all_dict)\n",
    "\n",
    "all_dict = s2s_all_dict\n",
    "\n",
    "all_dict['Reference'] = es_all_dict['Reference']\n",
    "all_dict['Hypothesis_es'] = es_all_dict['Hypothesis']\n",
    "all_dict['Hypothesis_trans'] = trans_all_dict['Hypothesis']\n",
    "# all_dict['Hypothesis_s2s'] = all_dict['Hypothesis']\n",
    "all_dict.rename(columns={'Hypothesis' : 'Hypothesis_s2s'}, inplace=True)\n",
    "# all_dict.drop(columns=['Hypothesis'], inplace=True)\n",
    "\n",
    "print(all_dict.shape)\n",
    "all_dict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "references = []\n",
    "hypothesis = []\n",
    "counts = [0, 0, 0]\n",
    "for idx in tqdm(range(all_dict.shape[0])):\n",
    "    try:\n",
    "        h, r, i = predict_pandas(all_dict, idx, do_predict=True)\n",
    "#         h, r,i  = predict_pandas(all_dict, idx, do_predict=False)\n",
    "        counts[i] += 1\n",
    "        references.append(r[r.nonzero()])\n",
    "        hypothesis.append(h[h.nonzero()])\n",
    "    except:\n",
    "        print(\"Skipping\", idx)\n",
    "        \n",
    "references = np.array(references)\n",
    "hypothesis = np.array(hypothesis)\n",
    "print(counts)\n",
    "eval_conf = get_evaluation_conf(None, hparams, None, None, voc_holder)\n",
    "evaluation = evaluate_words_index(references, hypothesis, eval_conf, hparams.evaluation_metrics, True)\n",
    "print(format_metrics(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = s2s_all_dict\n",
    "df['Hypothesis'] = list(map(voc_holder.from_word_idx, hypothesis))\n",
    "df.to_csv('data/ensamble_all_dict.tsv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 4034\n",
    "print(es_all_dict.ix[idx, 'Question'])\n",
    "print(trans_all_dict.ix[idx, 'Question'])\n",
    "print(s2s_all_dict.ix[idx, 'Question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(sess.run(c, feed_dict)[0]);\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = sess.run(S_T, feed_dict)[0].T\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 16), dpi= 80, facecolor='w', edgecolor='k')\n",
    "im = ax.imshow(a, cmap='hot', interpolation='nearest')\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange((a.shape[1])))\n",
    "ax.set_yticks(np.arange((a.shape[0])))\n",
    "\n",
    "# ... and label them with the respective list entries\n",
    "ax.set_xticklabels([voc_holder.reverse_vocab[x] for x in feed_dict[qry][0]])\n",
    "ax.set_yticklabels([voc_holder.reverse_vocab[x] for x in feed_dict[ctx][0]])\n",
    "\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "\n",
    "ax.set_title(\"Harvest of local farmers (in tons/year)\")\n",
    "fig.tight_layout()\n",
    "plt.colorbar(im)  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(c_emb, feed_dict)[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_holder.reverse_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(map(int, sess.run(c_mask, feed_dict)[0]))\n",
    "np.count_nonzero(feed_dict[ctx][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict[ctx][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(suppress=True)\n",
    "feed_dict = next_batch(train_x, train_y, 10)\n",
    "\n",
    "print(voc_holder.from_word_idx(feed_dict[qry][0]))\n",
    "print()\n",
    "print(voc_holder.from_word_idx(feed_dict[ctx][0]))\n",
    "\n",
    "print(sess.run(losses, feed_dict))\n",
    "\n",
    "# 1. / (1. + np.exp(-sess.run(logits, feed_dict=feed_dict)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Old code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "dropout = tf.placeholder_with_default(0.0, (), name=\"dropout\")\n",
    "\n",
    "p = tf.placeholder(dtype=tf.float32, shape=(None, 1), name=\"prob\")\n",
    "\n",
    "qry = tf.placeholder(dtype=tf.int32, shape=(None, q_maxlen), name=\"query\")\n",
    "ctx = tf.placeholder(dtype=tf.int32, shape=(None, c_maxlen), name=\"elastic\")\n",
    "\n",
    "with tf.variable_scope(\"Input_Embedding_Layer\"):\n",
    "#     pretrained_embs = tf.get_variable(\n",
    "#         name=\"embs_pretrained\",\n",
    "#         initializer=tf.constant_initializer(\n",
    "#            voc_holder.glove_weights, dtype=tf.float32),\n",
    "#         shape=voc_holder.glove_weights.shape,\n",
    "#         trainable=False)\n",
    "\n",
    "    elmo_tensor = tf.convert_to_tensor(elmo_weights)\n",
    "#     c_emb, _  = embed_tensor(ctx, pretrained_embs, \"embedding_ctx_glove\")\n",
    "#     q_emb, _  = embed_tensor(qry, pretrained_embs, \"embedding_qry_glove\")\n",
    "\n",
    "#     c_emb = tf.nn.dropout(c_emb, 1.0 - dropout) \n",
    "#     q_emb = tf.nn.dropout(q_emb, 1.0 - dropout) \n",
    "    c_emb = tf.nn.dropout(tf.nn.embedding_lookup(elmo_tensor, ctx), 1.0 - dropout)\n",
    "    q_emb = tf.nn.dropout(tf.nn.embedding_lookup(elmo_tensor, qry), 1.0 - dropout)\n",
    "\n",
    "#     c_emb = tf.reduce_mean(c_emb, 1)\n",
    "#     q_emb = tf.reduce_mean(q_emb, 1)\n",
    "\n",
    "inputs = tf.concat([c_emb, q_emb], 1)\n",
    "inputs = tf.reshape(inputs, (-1, 1024*hparams.encoder_length*2))\n",
    "logits = tf.layers.dense(inputs, 1, activation=tf.sigmoid, kernel_regularizer=regularizer)\n",
    "yp = tf.sigmoid(logits)\n",
    "correct_pred = tf.equal(tf.round(yp), p)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "# lr = tf.minimum(hparams.learning_rate, 0.001 / tf.log(999.) * tf.log(tf.cast(global_step, tf.float32) + 1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(.1)\n",
    "losses = tf.nn.sigmoid_cross_entropy_with_logits(labels = p, logits = logits)\n",
    "loss = tf.reduce_mean(losses)\n",
    "\n",
    "variables = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "l2_loss = tf.contrib.layers.apply_regularization(regularizer, variables)\n",
    "loss += l2_loss\n",
    "\n",
    "params = tf.trainable_variables()\n",
    "gradients = tf.gradients(loss, params)\n",
    "clipped_gradients, _ = tf.clip_by_global_norm(gradients,\n",
    "                                              hparams.max_gradient_norm)\n",
    "\n",
    "train_op = optimizer.apply_gradients(\n",
    "    zip(clipped_gradients, params), global_step=global_step)\n",
    "\n",
    "total_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_parameters = 0\n",
    "for variable in tf.trainable_variables():\n",
    "    # shape is an array of tf.Dimension\n",
    "    shape = variable.get_shape()\n",
    "#     print(shape)\n",
    "#     print(len(shape))\n",
    "    variable_parameters = 1\n",
    "    for dim in shape:\n",
    "#         print(dim)\n",
    "        variable_parameters *= dim.value\n",
    "#     print(variable_parameters)\n",
    "    total_parameters += variable_parameters\n",
    "print(\"{:,}\".format(total_parameters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class Model(object):\n",
    "    def __init__(self, config, batch, word_mat=None, char_mat=None, trainable=True, opt=True, demo = False, graph = None):\n",
    "        self.config = config\n",
    "        self.demo = demo\n",
    "        self.graph = graph if graph is not None else tf.Graph()\n",
    "        with self.graph.as_default():\n",
    "\n",
    "            self.global_step = tf.get_variable('global_step', shape=[], dtype=tf.int32,\n",
    "                                               initializer=tf.constant_initializer(0), trainable=False)\n",
    "            self.dropout = tf.placeholder_with_default(0.0, (), name=\"dropout\")\n",
    "#             if self.demo:\n",
    "#                 self.c = tf.placeholder(tf.int32, [None, config.test_para_limit],\"context\")\n",
    "#                 self.q = tf.placeholder(tf.int32, [None, config.test_ques_limit],\"question\")\n",
    "#                 self.ch = tf.placeholder(tf.int32, [None, config.test_para_limit, config.char_limit],\"context_char\")\n",
    "#                 self.qh = tf.placeholder(tf.int32, [None, config.test_ques_limit, config.char_limit],\"question_char\")\n",
    "#                 self.y1 = tf.placeholder(tf.int32, [None, config.test_para_limit],\"answer_index1\")\n",
    "#                 self.y2 = tf.placeholder(tf.int32, [None, config.test_para_limit],\"answer_index2\")\n",
    "#             else:\n",
    "#                 self.c, self.q, self.ch, self.qh, self.y1, self.y2, self.qa_id = batch.get_next()\n",
    "\n",
    "            inputs = [tf.placeholder(dtype=tf.int32, shape=(None, None), name=\"elastic\"),\n",
    "                 tf.placeholder(dtype=tf.int32, shape=(None, None), name=\"seq2seq\"),\n",
    "                 tf.placeholder(dtype=tf.int32, shape=(None, None), name=\"transformer\"),\n",
    "                 tf.placeholder(dtype=tf.int32, shape=(None, None), name=\"query\")]\n",
    "\n",
    "            # self.word_unk = tf.get_variable(\"word_unk\", shape = [config.glove_dim], initializer=initializer())\n",
    "            self.word_mat = tf.get_variable(\"word_mat\", initializer=tf.constant(\n",
    "                word_mat, dtype=tf.float32), trainable=False)\n",
    "            self.char_mat = tf.get_variable(\n",
    "                \"char_mat\", initializer=tf.constant(char_mat, dtype=tf.float32))\n",
    "\n",
    "            self.c_mask = tf.cast(self.c, tf.bool)\n",
    "            self.q_mask = tf.cast(self.q, tf.bool)\n",
    "            self.c_len = tf.reduce_sum(tf.cast(self.c_mask, tf.int32), axis=1)\n",
    "            self.q_len = tf.reduce_sum(tf.cast(self.q_mask, tf.int32), axis=1)\n",
    "\n",
    "            if opt:\n",
    "                N, CL = config.batch_size if not self.demo else 1, config.char_limit\n",
    "                self.c_maxlen = tf.reduce_max(self.c_len)\n",
    "                self.q_maxlen = tf.reduce_max(self.q_len)\n",
    "                self.c = tf.slice(self.c, [0, 0], [N, self.c_maxlen])\n",
    "                self.q = tf.slice(self.q, [0, 0], [N, self.q_maxlen])\n",
    "                self.c_mask = tf.slice(self.c_mask, [0, 0], [N, self.c_maxlen])\n",
    "                self.q_mask = tf.slice(self.q_mask, [0, 0], [N, self.q_maxlen])\n",
    "                self.ch = tf.slice(self.ch, [0, 0, 0], [N, self.c_maxlen, CL])\n",
    "                self.qh = tf.slice(self.qh, [0, 0, 0], [N, self.q_maxlen, CL])\n",
    "                self.y1 = tf.slice(self.y1, [0, 0], [N, self.c_maxlen])\n",
    "                self.y2 = tf.slice(self.y2, [0, 0], [N, self.c_maxlen])\n",
    "            else:\n",
    "                self.c_maxlen, self.q_maxlen = config.para_limit, config.ques_limit\n",
    "\n",
    "            self.ch_len = tf.reshape(tf.reduce_sum(\n",
    "                tf.cast(tf.cast(self.ch, tf.bool), tf.int32), axis=2), [-1])\n",
    "            self.qh_len = tf.reshape(tf.reduce_sum(\n",
    "                tf.cast(tf.cast(self.qh, tf.bool), tf.int32), axis=2), [-1])\n",
    "\n",
    "            self.forward()\n",
    "            total_params()\n",
    "\n",
    "            if trainable:\n",
    "                self.lr = tf.minimum(config.learning_rate, 0.001 / tf.log(999.) * tf.log(tf.cast(self.global_step, tf.float32) + 1))\n",
    "                self.opt = tf.train.AdamOptimizer(learning_rate = self.lr, beta1 = 0.8, beta2 = 0.999, epsilon = 1e-7)\n",
    "                grads = self.opt.compute_gradients(self.loss)\n",
    "                gradients, variables = zip(*grads)\n",
    "                capped_grads, _ = tf.clip_by_global_norm(\n",
    "                    gradients, config.grad_clip)\n",
    "                self.train_op = self.opt.apply_gradients(\n",
    "                    zip(capped_grads, variables), global_step=self.global_step)\n",
    "\n",
    "    def forward(self):\n",
    "        config = self.config\n",
    "        N, PL, QL, CL, d, dc, nh = config.batch_size if not self.demo else 1, self.c_maxlen, self.q_maxlen, config.char_limit, config.hidden, config.char_dim, config.num_heads\n",
    "\n",
    "        with tf.variable_scope(\"Input_Embedding_Layer\"):\n",
    "            ch_emb = tf.reshape(tf.nn.embedding_lookup(\n",
    "                self.char_mat, self.ch), [N * PL, CL, dc])\n",
    "            qh_emb = tf.reshape(tf.nn.embedding_lookup(\n",
    "                self.char_mat, self.qh), [N * QL, CL, dc])\n",
    "            ch_emb = tf.nn.dropout(ch_emb, 1.0 - 0.5 * self.dropout)\n",
    "            qh_emb = tf.nn.dropout(qh_emb, 1.0 - 0.5 * self.dropout)\n",
    "\n",
    "            # Bidaf style conv-highway encoder\n",
    "            ch_emb = conv(ch_emb, d,\n",
    "                bias = True, activation = tf.nn.relu, kernel_size = 5, name = \"char_conv\", reuse = None)\n",
    "            qh_emb = conv(qh_emb, d,\n",
    "                bias = True, activation = tf.nn.relu, kernel_size = 5, name = \"char_conv\", reuse = True)\n",
    "\n",
    "            ch_emb = tf.reduce_max(ch_emb, axis = 1)\n",
    "            qh_emb = tf.reduce_max(qh_emb, axis = 1)\n",
    "\n",
    "            ch_emb = tf.reshape(ch_emb, [N, PL, ch_emb.shape[-1]])\n",
    "            qh_emb = tf.reshape(qh_emb, [N, QL, ch_emb.shape[-1]])\n",
    "\n",
    "            c_emb = tf.nn.dropout(tf.nn.embedding_lookup(self.word_mat, self.c), 1.0 - self.dropout)\n",
    "            q_emb = tf.nn.dropout(tf.nn.embedding_lookup(self.word_mat, self.q), 1.0 - self.dropout)\n",
    "\n",
    "            c_emb = tf.concat([c_emb, ch_emb], axis=2)\n",
    "            q_emb = tf.concat([q_emb, qh_emb], axis=2)\n",
    "\n",
    "            c_emb = highway(c_emb, size = d, scope = \"highway\", dropout = self.dropout, reuse = None)\n",
    "            q_emb = highway(q_emb, size = d, scope = \"highway\", dropout = self.dropout, reuse = True)\n",
    "\n",
    "        with tf.variable_scope(\"Embedding_Encoder_Layer\"):\n",
    "            c = residual_block(c_emb,\n",
    "                num_blocks = 1,\n",
    "                num_conv_layers = 4,\n",
    "                kernel_size = 7,\n",
    "                mask = self.c_mask,\n",
    "                num_filters = d,\n",
    "                num_heads = nh,\n",
    "                seq_len = self.c_len,\n",
    "                scope = \"Encoder_Residual_Block\",\n",
    "                bias = False,\n",
    "                dropout = self.dropout)\n",
    "            q = residual_block(q_emb,\n",
    "                num_blocks = 1,\n",
    "                num_conv_layers = 4,\n",
    "                kernel_size = 7,\n",
    "                mask = self.q_mask,\n",
    "                num_filters = d,\n",
    "                num_heads = nh,\n",
    "                seq_len = self.q_len,\n",
    "                scope = \"Encoder_Residual_Block\",\n",
    "                reuse = True, # Share the weights between passage and question\n",
    "                bias = False,\n",
    "                dropout = self.dropout)\n",
    "\n",
    "        with tf.variable_scope(\"Context_to_Query_Attention_Layer\"):\n",
    "            # C = tf.tile(tf.expand_dims(c,2),[1,1,self.q_maxlen,1])\n",
    "            # Q = tf.tile(tf.expand_dims(q,1),[1,self.c_maxlen,1,1])\n",
    "            # S = trilinear([C, Q, C*Q], input_keep_prob = 1.0 - self.dropout)\n",
    "            S = optimized_trilinear_for_attention([c, q], self.c_maxlen, self.q_maxlen, input_keep_prob = 1.0 - self.dropout)\n",
    "            mask_q = tf.expand_dims(q_mask, 1)\n",
    "            S_ = tf.nn.softmax(mask_logits(S, mask = mask_q))\n",
    "            mask_c = tf.expand_dims(c_mask, 2)\n",
    "            S_T = tf.transpose(tf.nn.softmax(mask_logits(S, mask = mask_c), dim = 1),(0,2,1))\n",
    "            c2q = tf.matmul(S_, q)\n",
    "            q2c = tf.matmul(tf.matmul(S_, S_T), c)\n",
    "            attention_outputs = [c, c2q, c * c2q, c * self.q2c]\n",
    "\n",
    "        with tf.variable_scope(\"Model_Encoder_Layer\"):\n",
    "            inputs = tf.concat(attention_outputs, axis = -1)\n",
    "            self.enc = [conv(inputs, d, name = \"input_projection\")]\n",
    "            for i in range(3):\n",
    "                if i % 2 == 0: # dropout every 2 blocks\n",
    "                    self.enc[i] = tf.nn.dropout(self.enc[i], 1.0 - self.dropout)\n",
    "                self.enc.append(\n",
    "                    residual_block(self.enc[i],\n",
    "                        num_blocks = 7,\n",
    "                        num_conv_layers = 2,\n",
    "                        kernel_size = 5,\n",
    "                        mask = self.c_mask,\n",
    "                        num_filters = d,\n",
    "                        num_heads = nh,\n",
    "                        seq_len = self.c_len,\n",
    "                        scope = \"Model_Encoder\",\n",
    "                        bias = False,\n",
    "                        reuse = True if i > 0 else None,\n",
    "                        dropout = self.dropout)\n",
    "                    )\n",
    "\n",
    "        with tf.variable_scope(\"Output_Layer\"):\n",
    "            start_logits = tf.squeeze(conv(tf.concat([self.enc[1], self.enc[2]],axis = -1),1, bias = False, name = \"start_pointer\"),-1)\n",
    "            end_logits = tf.squeeze(conv(tf.concat([self.enc[1], self.enc[3]],axis = -1),1, bias = False, name = \"end_pointer\"), -1)\n",
    "            self.logits = [mask_logits(start_logits, mask = self.c_mask),\n",
    "                           mask_logits(end_logits, mask = self.c_mask)]\n",
    "\n",
    "            logits1, logits2 = [l for l in self.logits]\n",
    "\n",
    "            outer = tf.matmul(tf.expand_dims(tf.nn.softmax(logits1), axis=2),\n",
    "                              tf.expand_dims(tf.nn.softmax(logits2), axis=1))\n",
    "            outer = tf.matrix_band_part(outer, 0, config.ans_limit)\n",
    "            self.yp1 = tf.argmax(tf.reduce_max(outer, axis=2), axis=1)\n",
    "            self.yp2 = tf.argmax(tf.reduce_max(outer, axis=1), axis=1)\n",
    "            losses = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                logits=logits1, labels=self.y1)\n",
    "            losses2 = tf.nn.softmax_cross_entropy_with_logits(\n",
    "                logits=logits2, labels=self.y2)\n",
    "            self.loss = tf.reduce_mean(losses + losses2)\n",
    "\n",
    "        if config.l2_norm is not None:\n",
    "            variables = tf.get_collection(tf.GraphKeys.REGULARIZATION_LOSSES)\n",
    "            l2_loss = tf.contrib.layers.apply_regularization(regularizer, variables)\n",
    "            self.loss += l2_loss\n",
    "\n",
    "        if config.decay is not None:\n",
    "            self.var_ema = tf.train.ExponentialMovingAverage(config.decay)\n",
    "            ema_op = self.var_ema.apply(tf.trainable_variables())\n",
    "            with tf.control_dependencies([ema_op]):\n",
    "                self.loss = tf.identity(self.loss)\n",
    "\n",
    "                self.assign_vars = []\n",
    "                for var in tf.global_variables():\n",
    "                    v = self.var_ema.average(var)\n",
    "                    if v:\n",
    "                        self.assign_vars.append(tf.assign(var,v))\n",
    "\n",
    "    def get_loss(self):\n",
    "        return self.loss\n",
    "\n",
    "    def get_global_step(self):\n",
    "        return self.global_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "elmo_weights[customersupport.common.utils.PAD] = np.zeros(1024, dtype=np.float32)\n",
    "\n",
    "elmo_tensor = tf.convert_to_tensor(elmo_weights)\n",
    "\n",
    "inputs = [tf.placeholder(dtype=tf.int32, shape=(None, None), name=\"elastic\"),\n",
    "         tf.placeholder(dtype=tf.int32, shape=(None, None), name=\"seq2seq\"),\n",
    "         tf.placeholder(dtype=tf.int32, shape=(None, None), name=\"transformer\"),\n",
    "         tf.placeholder(dtype=tf.int32, shape=(None, None), name=\"query\")]\n",
    "batch_size = tf.shape(inputs[0])[0]\n",
    "\n",
    "input_keep_prob = tf.constant(.8)\n",
    "\n",
    "outputs = tf.placeholder(dtype=tf.float32, shape=(None, 1024), name=\"outputs\")\n",
    "o_probs = tf.placeholder(dtype=tf.float32, shape=(None, 3), name=\"o_probs\")\n",
    "\n",
    "encoders = []\n",
    "masks = []\n",
    "for i, inp in enumerate(inputs):\n",
    "    with tf.variable_scope(\"model\", reuse=tf.AUTO_REUSE):\n",
    "        embedded_word_ids = tf.nn.embedding_lookup(elmo_tensor, inp)\n",
    "        mask = tf.to_float(tf.sign(inputs[i]))\n",
    "        e = build_encoder(embedded_word_ids, mask, 1, input_keep_prob, 1024, 128, 1, 32, 32, True)\n",
    "        encoders.append(e)\n",
    "        masks.append(mask)\n",
    "\n",
    "ctx = []\n",
    "query = encoders.pop()\n",
    "mask_q = masks[-1]\n",
    "for i, enc in enumerate(encoders):\n",
    "    with tf.variable_scope(\"model\", reuse=(i != 0)):\n",
    "        mask_c = masks[i]\n",
    "        c2q = context2query(enc, query, mask_c, mask_q, input_keep_prob)\n",
    "#         cl = linear(c2q, 60)\n",
    "       \n",
    "        lstm = tf.contrib.rnn.LSTMCell(512)\n",
    "        initial_state = lstm.zero_state(batch_size, tf.float32)\n",
    "        lstm_outputs, final_state = tf.nn.dynamic_rnn(lstm, c2q[2], initial_state=initial_state)\n",
    "        \n",
    "        ctx.append(lstm_outputs[:, -1])\n",
    "\n",
    "\n",
    "output = tf.reshape(tf.stack(ctx, 1), (-1, len(ctx), 512))\n",
    "logits = tf.squeeze(tf.layers.dense(output, 1, use_bias=False))\n",
    "# print(output.get_shape())\n",
    "# logits = tf.nn.softmax(logits)\n",
    "# logits = tf.expand_dims(logits, 2)\n",
    "\n",
    "# y_pred = tf.squeeze(tf.matmul(logits, output, transpose_a=True))\n",
    "\n",
    "# y_pred_norm = tf.sqrt(tf.reduce_sum(tf.square(y_pred), axis=1, keepdims=True) + 1e-8)\n",
    "# outputs_norm = tf.sqrt(tf.reduce_sum(tf.square(outputs), axis=1, keepdims=True) + 1e-8)\n",
    "\n",
    "# train_loss = tf.reduce_mean(tf.squared_difference(y_pred, outputs)) \n",
    "# train_loss += tf.norm(y_pred - outputs, ord='euclidean')\n",
    "# train_loss += 0.01 * tf.losses.cosine_distance(y_pred_norm, outputs_norm, axis=1)\n",
    "y_smooted = o_probs#label_smoothing(o_probs)\n",
    "\n",
    "crossent = tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "    labels=y_smooted, logits=logits)\n",
    "train_loss = tf.reduce_mean(crossent)\n",
    "\n",
    "# Train\n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "# Calculate and clip gradients\n",
    "params = tf.trainable_variables()\n",
    "gradients = tf.gradients(train_loss, params)\n",
    "clipped_gradients, _ = tf.clip_by_global_norm(gradients,\n",
    "                                              hparams.max_gradient_norm)\n",
    "\n",
    "# Optimization\n",
    "learning_rate = tf.train.exponential_decay(\n",
    "    hparams.learning_rate, global_step, iters_per_epoch, .99, staircase=True)\n",
    "# learning_rate = tf.Variable(0.001, dtype=np.float32)\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer()\n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train_op = optimizer.apply_gradients(\n",
    "    zip(clipped_gradients, params), global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = evaluate(test_x, test_y, eval_conf_greedy, hparams.evaluation_metrics, True)\n",
    "print(format_metrics(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# cnt = Counter()\n",
    "\n",
    "for i in tqdm(range(2000)):\n",
    "    feed_dict = next_batch(train_x, train_y, 64)\n",
    "    o1 = sess.run([train_loss, train_op], feed_dict=feed_dict)\n",
    "    if i % 10 == 0:\n",
    "        print(o1[0], end='..')\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feed_dict = next_batch(train_x, train_y, 2)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15,15]\n",
    "\n",
    "ctxt = feed_dict[inputs[2]][0]\n",
    "qtxt = feed_dict[inputs[3]][0]\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "im = ax.imshow(sess.run(c2q, feed_dict=feed_dict)[4][0], cmap='binary', interpolation='nearest')\n",
    "\n",
    "# We want to show all ticks...\n",
    "ax.set_xticks(np.arange(len(qtxt)))\n",
    "ax.set_yticks(np.arange(len(ctxt)))\n",
    "# ... and label them with the respective list entries\n",
    "ax.set_xticklabels([voc_holder.reverse_vocab[i] for i in qtxt])\n",
    "ax.set_yticklabels([voc_holder.reverse_vocab[i] for i in ctxt])\n",
    "plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "         rotation_mode=\"anchor\")\n",
    "plt.show()\n",
    "# print(feed_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export(x, y, eval_conf):\n",
    "    verbose = True\n",
    "    references = []\n",
    "    hypothesis = []\n",
    "    losses = []\n",
    "    questions = []\n",
    "\n",
    "    batch_size = eval_conf.batch_size\n",
    "    beam_width = eval_conf.beam_width\n",
    "\n",
    "    batch_ids = get_batch_id_chunks(len(x), batch_size)\n",
    "\n",
    "    gen = range(len(batch_ids))\n",
    "    exclude = set(string.punctuation)\n",
    "\n",
    "    if (verbose):\n",
    "        gen = tqdm(gen)\n",
    "\n",
    "    for i in gen:\n",
    "        feed_dict = next_batch(x, y, False,\n",
    "            rand_idx=batch_ids[i], \n",
    "            weights=None,\n",
    "            beam_width=beam_width)\n",
    "        \n",
    "        responses = sess.run(eval_conf.seq_func, feed_dict=feed_dict)[0]\n",
    "        feed_dict[beam_width_tensor] = 1\n",
    "        loss = sess.run(tf.reduce_mean(crossent * target_weights, 1), feed_dict=feed_dict)\n",
    "\n",
    "        for (h, r, q, l) in zip(responses, feed_dict.get(target_labels), feed_dict.get(encoder_inputs), loss):\n",
    "            references.append(voc_holder.from_word_idx(strip_punkt(r, eval_conf.voc_holder.reverse_vocab)))\n",
    "            hypothesis.append(voc_holder.from_word_idx(strip_punkt(h, eval_conf.voc_holder.reverse_vocab)))\n",
    "            questions.append(voc_holder.from_word_idx(q))\n",
    "            losses.append(l)\n",
    "        print('{}'.format(len(losses)), end='...')\n",
    "            \n",
    "    return (np.array(questions), np.array(references), np.array(hypothesis), np.array(losses))\n",
    "\n",
    "(q, r, h, l) = export(test_x, test_y, eval_conf)\n",
    "df = pd.DataFrame(data = np.vstack((q, r, h, l)).T, \n",
    "                 columns = [\"Question\", \"Reference\", \"Hypothesis\", \"Loss\" ])\n",
    "df.head()\n",
    "df.to_csv('/home/momchil/Desktop/seq2seq_all_dict.tsv', sep='\\t', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "MIN_INT = (-2 ** 32 + 1)\n",
    "\n",
    "\n",
    "def pos_embeddings(d_model: int, timesteps: int) -> tf.Tensor:\n",
    "    lookup_table = np.zeros(shape=(timesteps, d_model), dtype=np.float32)\n",
    "    for pos in range(timesteps):\n",
    "        pos_vec = lookup_table[pos]\n",
    "        for i in range(d_model):\n",
    "            val = pos / (1000 ** (2 * i / d_model))\n",
    "            pos_vec[i] = np.sin(val) if i % 2 == 0 else np.cos(val)\n",
    "\n",
    "    return tf.convert_to_tensor(lookup_table)\n",
    "\n",
    "\n",
    "def embedding_layer(inputs: tf.Tensor, vocabulary_size: int, embedding_size: int, dropout_rate: float,\n",
    "                    is_training: bool, scope: str) -> tf.Tensor:\n",
    "    with tf.variable_scope(scope, \"Embeddings\"):\n",
    "        word_embeddings = tf.get_variable(\"word_embeddings\",\n",
    "                                          [vocabulary_size, embedding_size])\n",
    "        embedded_word_ids = tf.nn.embedding_lookup(word_embeddings, inputs)\n",
    "        emb = tf.layers.dropout(embedded_word_ids, rate=dropout_rate, training=tf.convert_to_tensor(is_training))\n",
    "\n",
    "        return emb\n",
    "\n",
    "\n",
    "def mask_matrix(masks: tf.Tensor, outputs: tf.Tensor, dims: int) -> tf.Tensor:\n",
    "    masks = tf.tile(tf.expand_dims(masks, 1), [1, dims, 1])\n",
    "\n",
    "    paddings = tf.ones_like(outputs) * MIN_INT\n",
    "    logits = tf.where(tf.equal(masks, 0), paddings, outputs)\n",
    "\n",
    "    return logits\n",
    "\n",
    "\n",
    "def multihead_attention(queries: tf.Tensor, keys: tf.Tensor, masks: tf.Tensor, dropout_rate: float, h: int, d_v: int,\n",
    "                        d_k: int, causality: bool, is_training: bool, scope: str = None) -> tf.Tensor:\n",
    "    with tf.variable_scope(scope, \"multi-head-attn\"):\n",
    "        q = tf.layers.dense(queries, d_k, use_bias=False)\n",
    "        k = tf.layers.dense(keys, d_k, use_bias=False)\n",
    "        v = tf.layers.dense(keys, d_k, use_bias=False)\n",
    "\n",
    "        outputs = tf.matmul(q, k, transpose_b=True) / np.sqrt(d_k)\n",
    "\n",
    "        # Key Masking\n",
    "#         masks = tf.sign(tf.abs(tf.reduce_sum(keys, axis=-1)))\n",
    "        logits = mask_matrix(masks, outputs, tf.shape(queries)[1])\n",
    "        if causality:\n",
    "            ltrig = tf.matrix_band_part(logits, -1, 0)\n",
    "            paddings = tf.ones_like(outputs) * MIN_INT\n",
    "            logits = tf.where(tf.equal(ltrig, 0), paddings, outputs)\n",
    "\n",
    "        att_w = tf.nn.softmax(logits)\n",
    "        \n",
    "        query_masks = tf.sign(tf.abs(tf.reduce_sum(queries, axis=-1)))\n",
    "        query_masks = tf.tile(tf.expand_dims(query_masks, -1), [1, 1, tf.shape(keys)[1]])\n",
    "        att_w *= query_masks\n",
    "\n",
    "        att_w = tf.layers.dropout(att_w, rate=dropout_rate, training=tf.convert_to_tensor(is_training))\n",
    "\n",
    "        values = tf.matmul(att_w, v)\n",
    "\n",
    "        return values\n",
    "\n",
    "def multihead_layer(query: tf.Tensor, keys: tf.Tensor, masks: tf.Tensor, dropout_rate: float, h: int, d_model: int, d_k: int, d_v: int,\n",
    "                    causality: bool = False, is_training: bool = False) -> tf.Tensor:\n",
    "    heads = [multihead_attention(query, keys, masks, dropout_rate,\n",
    "                                 h, d_k, d_v, causality, is_training,\n",
    "                                 \"multi-head-attn\" + str(i))\n",
    "             for i in range(h)]\n",
    "    heads = tf.concat(heads, axis=-1)\n",
    "\n",
    "    mha = tf.layers.dense(heads, d_model, use_bias=False)\n",
    "    norm_mha = tf.contrib.layers.layer_norm(mha + query)\n",
    "\n",
    "    norm_mha = tf.layers.dropout(norm_mha, rate=dropout_rate, training=tf.convert_to_tensor(is_training))\n",
    "\n",
    "    return norm_mha\n",
    "\n",
    "\n",
    "def feed_forward(inputs: tf.Tensor, d_ff: int, d_model: int, scope: str = None) -> tf.Tensor:\n",
    "    with tf.variable_scope(scope, \"feed-forward\"):\n",
    "        proj = tf.layers.dense(inputs, d_ff, activation=tf.nn.relu, use_bias=True)\n",
    "        ff = tf.layers.dense(proj, d_model, use_bias=True)\n",
    "\n",
    "        out = tf.contrib.layers.layer_norm(ff + inputs)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "def build_encoder(enc: tf.Tensor, masks: tf.Tensor, n_blocks: int, dropout_rate: float, d_model: int, d_ff: \n",
    "                  int, h: int, d_k: int, d_v: int, is_training: bool) -> tf.Tensor:\n",
    "    if n_blocks <= 0:\n",
    "        return enc\n",
    "\n",
    "    with tf.variable_scope(\"encoder\" + str(n_blocks)):\n",
    "        norm_mha = multihead_layer(enc, enc, masks, dropout_rate, h, d_model, d_k, d_v, False, is_training)\n",
    "        enc = feed_forward(norm_mha, d_ff, d_model, \"feed-forward\")\n",
    "\n",
    "    return build_encoder(enc, masks, n_blocks - 1, dropout_rate, d_model, d_ff, h, d_k, d_v, is_training)\n",
    "\n",
    "\n",
    "def build_decoder(dec: tf.Tensor, enc: tf.Tensor, n_blocks: int, dropout_rate: float, d_model: int, d_ff: int,\n",
    "                  h: int, d_k: int, d_v: int, is_training: bool) -> tf.Tensor:\n",
    "    if n_blocks <= 0:\n",
    "        return dec\n",
    "\n",
    "    with tf.variable_scope(\"decoder\" + str(n_blocks)):\n",
    "        with tf.variable_scope(\"self-attention\"):\n",
    "            self_att = multihead_layer(dec, dec, dropout_rate, h, d_model, d_k, d_v, True,\n",
    "                                       is_training)\n",
    "\n",
    "        with tf.variable_scope(\"mha-attention\"):\n",
    "            norm_mha = multihead_layer(self_att, enc, dropout_rate, h, d_model, d_k, d_v, False,\n",
    "                                       is_training)\n",
    "\n",
    "            dec = feed_forward(norm_mha, d_ff, d_model, \"feed-forward\")\n",
    "\n",
    "    return build_decoder(dec, enc, n_blocks - 1, dropout_rate, d_model, d_ff, h, d_k, d_v, is_training)\n",
    "\n",
    "\n",
    "def label_smoothing(y: tf.Tensor, epsilon: float = 0.1) -> tf.Tensor:\n",
    "    with tf.variable_scope(\"smoothing\"):\n",
    "        k = y.get_shape().as_list()[-1]\n",
    "\n",
    "        return y * (1 - epsilon) + (epsilon / k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
