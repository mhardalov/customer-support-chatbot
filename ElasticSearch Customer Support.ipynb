{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/momchil/.local/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Library versions:\n",
      "tensorflow:1.7.0\n",
      "pandas:0.22.0\n",
      "numpy:1.14.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a980acdbd4a4483bdb9e698c11c48cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import random\n",
    "import string\n",
    "import warnings\n",
    "\n",
    "import importlib\n",
    "\n",
    "import customersupport.common\n",
    "import customersupport.evaluation\n",
    "import customersupport.evaluation.eval\n",
    "\n",
    "print('Library versions:')\n",
    "\n",
    "import tensorflow as tf\n",
    "print('tensorflow:{}'.format(tf.__version__))\n",
    "import pandas as pd\n",
    "print('pandas:{}'.format(pd.__version__))\n",
    "import numpy as np\n",
    "print('numpy:{}'.format(np.__version__))\n",
    "\n",
    "from IPython.display import SVG\n",
    "\n",
    "from tqdm import tqdm_notebook as tqdm  # Special jupyter notebook progress bar\n",
    "\n",
    "from tensorflow.python.layers import core as layers_core\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch import helpers\n",
    "\n",
    "from customersupport.common.vocab import VocabHolder\n",
    "from customersupport.common.dataset import CustomerSupportDataset\n",
    "\n",
    "from customersupport.evaluation.eval import evaluate_words_index, format_metrics, get_evaluation_conf, strip_punkt\n",
    "\n",
    "importlib.reload(customersupport.common.vocab)\n",
    "importlib.reload(customersupport.common.dataset)\n",
    "importlib.reload(customersupport.evaluation)\n",
    "importlib.reload(customersupport.evaluation.eval)\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "tqdm().pandas()  # Enable tracking of progress in dataframe `apply` calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/momchil/.local/lib/python3.5/site-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:198: retry (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use the retry module or similar alternatives.\n"
     ]
    }
   ],
   "source": [
    "# 8192 - large enough for demonstration, larger values make network training slower\n",
    "MAX_VOCAB_SIZE = 2**14\n",
    "# seq2seq generally relies on fixed length message vectors - longer messages provide more info\n",
    "# but result in slower training and larger networks\n",
    "MAX_MESSAGE_LEN = 70\n",
    "\n",
    "hparams = tf.contrib.training.HParams(\n",
    "    # Larger batch sizes generally reach the average response faster, but small batch sizes are\n",
    "    # required for the model to learn nuanced responses.  Also, GPU memory limits max batch size.\n",
    "    batch_size=128,\n",
    "    encoder_length=MAX_MESSAGE_LEN,\n",
    "    decoder_length=MAX_MESSAGE_LEN,\n",
    "    # Embedding size for whole messages, same trade off as word embeddings\n",
    "    num_units=512,\n",
    "    src_vocab_size=MAX_VOCAB_SIZE,\n",
    "    # Embedding size for words - gives a trade off between expressivity of words and network size\n",
    "    embedding_size=200,\n",
    "    tgt_vocab_size=MAX_VOCAB_SIZE,\n",
    "    # Helps regularize network and prevent overfitting.\n",
    "    # High learning rate helps model reach average response faster, but can make it hard to \n",
    "    # converge on nuanced responses\n",
    "    learning_rate = 1e-04, #0.0005,\n",
    "    max_gradient_norm = 5.0,\n",
    "    beam_width = 10,\n",
    "    use_attention = True,\n",
    "    enc_num_layers = 2,\n",
    "    dec_num_layers = 2,\n",
    "    cell_type = 'bi',\n",
    "    rnn_type = 'gru',\n",
    "    max_epochs = 15,\n",
    "    dropout = 0.2,\n",
    "    use_glove = True,\n",
    "    l2_reg = 0.,\n",
    "    decay_rate = .9,\n",
    "    glove_path = '/home/momchil/Storage/Projects/Python/Data/glove.twitter.27B/glove.twitter.27B.200d.txt',\n",
    "    tweets_path = '/home/momchil/Storage/Projects/Python/Data/customer-support-on-twitter/twcs-conv_ids_clean.csv',\n",
    "    # Ngram count for ROUGE and BLEU\n",
    "    max_order = 2,\n",
    "    train_size = 0.8,\n",
    "    train_time_diff = 5.,\n",
    "    first_day = 0, #5#15\n",
    "    last_day = 60, #33#23,\n",
    "    evaluation_metrics = [\"bleu\", \"rouge_l\", \"embedding_average\", \"vector_extrema\", \"greedy_matching\"],\n",
    "    training_metrics = [\"bleu\", \"rouge_l\", \"embedding_average\", \"vector_extrema\", \"greedy_matching\"],\n",
    "    companies = ['AppleSupport']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done support_author (984679, 9)\n",
      "Replacing anonymized screen names in X...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dff3f578575b4381995ef440e59e79e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105179), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Replacing anonymized screen names in Y...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd37d23eb76b453682a55d034612d09f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=105179), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CPU times: user 3min 3s, sys: 1.98 s, total: 3min 5s\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cs_data = CustomerSupportDataset(hparams)\n",
    "\n",
    "#& (y_text.str.contains('help') ^ True)\n",
    "cs_data.process_utterances(['direct message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting CountVectorizer on X and Y text data...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa02c6932f94b1d95da6ba3d29acc93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=49626), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of known words 13796\n",
      "Learned vocab of 16384 items.\n"
     ]
    }
   ],
   "source": [
    "voc_holder = VocabHolder(hparams)\n",
    "analyzer = voc_holder.fit(cs_data.x_text, cs_data.y_text, hparams.src_vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aed68ed70454534a42beb6e1fb2b22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=13796), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-954d938bbb8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_holder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munk_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_holder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#voc_holder.vocab['información']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvoc_holder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_glove_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvoc_holder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglove_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvoc_holder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse_vocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1372\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1373\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1374\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1375\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1625\u001b[0m         \u001b[0;31m# fall thru to straight lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1626\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_valid_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1627\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1628\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[0;34m(self, label, axis)\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no slices here, handle elsewhere'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mxs\u001b[0;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[1;32m   2342\u001b[0m                                                       drop_level=drop_level)\n\u001b[1;32m   2343\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2344\u001b[0;31m             \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2346\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2523\u001b[0m                                  'backfill or nearest lookups')\n\u001b[1;32m   2524\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2525\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2526\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2527\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#voc_holder.glove_weights['información']\n",
    "#voc_holder.vocab['información']\n",
    "\n",
    "#voc_holder.glove_weights[13895 - voc_holder.unk_count]\n",
    "for i in tqdm(range(voc_holder.unk_count, len(voc_holder.vocab))):\n",
    "    #voc_holder.vocab['información']\n",
    "    assert np.array_equal(voc_holder.get_glove_weight(i), voc_holder.glove_words.loc[voc_holder.reverse_vocab[i]].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#información -0.70397 0.18217 -0.064088 -0.0056588 0.51003 -0.10394 -0.42054 -0.34863 -0.17556 0.14012 0.80545 -0.084485 0.93872 0.029406 0.65709 -0.062524 0.049807 -0.20443 1.066 0.41751 -0.21147 -0.93464 0.10176 -0.0032734 0.16059 -2.5545 0.45048 -0.31093 -0.047943 0.19738 -0.37638 -0.34054 -0.40261 -0.22547 0.22389 0.15547 -0.48353 0.21042 -0.89683 -0.16658 -0.54625 0.084119 0.29465 0.53094 0.28825 0.24623 0.52789 0.1222 -0.78786 0.10983 0.18148 -0.17835 -0.033985 0.077592 -0.88948 0.2255 -0.035032 -0.34115 0.0091689 0.24191 0.15341 -0.084803 0.5622 0.96704 0.77437 0.84728 0.068289 -0.028839 0.50977 -0.22183 -0.25135 -0.32503 0.86078 -0.95383 -0.45049 -0.058383 0.3746 -0.54584 -0.48925 -0.28214 -0.3099 0.25639 0.46344 -0.53287 0.40488 -0.10087 -0.74409 -0.40578 0.28525 0.30872 -0.42433 0.38774 -0.13566 0.11796 0.081923 -0.2832 -0.0072533 0.19522 -0.098084 -0.5526 -0.0634 0.27517 -0.4435 -0.0083655 0.24503 -0.67493 -1.4786 -0.18219 0.22464 -0.36414 0.19137 0.080971 -0.079933 0.22319 0.97154 0.94297 -0.52906 0.96633 0.35895 0.33781 -0.46276 0.79585 0.69646 0.031073 0.39987 -0.21439 0.055769 0.49177 0.47638 -0.21456 0.42292 -0.12287 -0.012149 0.81339 0.41095 -0.44385 0.08316 -0.20046 0.66937 0.38491 0.13405 0.21944 0.17057 -0.42101 0.24932 -0.52619 0.22774 -0.47653 -1.0329 0.016041 -0.74861 -0.35379 -0.80166 0.27047 -0.69027 -0.063318 0.85249 -0.20612 -0.74476 0.031826 -0.017643 -0.22145 -0.028813 0.79223 0.63236 0.3902 -0.86664 0.29952 -0.23364 -0.48895 0.51829 0.47168 -0.26713 -0.35187 -0.42353 -0.016235 0.38586 0.25133 -0.37427 0.3312 0.39023 -0.69639 0.36957 0.0059467 -0.32109 0.6286 -0.67398 -0.1552 0.085883 0.33042 0.42234 0.17393 -0.46704 -0.18503 1.0627 0.41987 -0.36343 -0.11899 -0.45553 0.6923\n",
    "# v.glove_weights[v.vocab['información']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating word indexes for X...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18801b8cf3244de5ae9aee8073760bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=49626), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating word indexes for Y...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd3392e57f7243768377d82063f663b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=49626), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training data of shape (45582, 70) and test data of shape (4044, 70).\n",
      "count    45582.000000\n",
      "mean         1.000000\n",
      "std          1.318587\n",
      "min          0.019216\n",
      "25%          0.123510\n",
      "50%          0.566117\n",
      "75%          1.191551\n",
      "max          6.313764\n",
      "dtype: float64\n",
      "count    4044.000000\n",
      "mean        1.000000\n",
      "std         0.151071\n",
      "min         0.737908\n",
      "25%         0.878444\n",
      "50%         1.003007\n",
      "75%         1.116925\n",
      "max         1.249495\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "cs_data.text_to_vec(hparams, voc_holder)\n",
    "cs_data.train_test_split(hparams, do_random=False)\n",
    "\n",
    "train_x = cs_data.x_text.iloc[list(cs_data.train_idx)].dropna()\n",
    "train_y = cs_data.y_text.iloc[list(cs_data.train_idx)].dropna()\n",
    "\n",
    "test_x = cs_data.x_text.iloc[list(cs_data.test_idx)].dropna()\n",
    "test_y = cs_data.y_text.iloc[list(cs_data.test_idx)].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_doc(text_x, text_y, context, author):\n",
    "    doc = {}\n",
    "    doc['author'] = author\n",
    "    doc['text_x'] = text_x\n",
    "    doc['text_y'] = text_y\n",
    "    doc['context'] = context\n",
    "    doc['timestamp'] = datetime.now()\n",
    "\n",
    "    return doc\n",
    "\n",
    "\n",
    "def create_index(es):\n",
    "    res = es.indices.delete(index='test-index', ignore=[400, 404])\n",
    "    mapping = '''\n",
    "    {  \n",
    "      \"mappings\":{  \n",
    "        \"tweet\":{  \n",
    "          \"properties\":{  \n",
    "            \"text_x\": { \n",
    "              \"type\": \"text\",\n",
    "              \"fields\": {\n",
    "                \"english\": { \n",
    "                  \"type\":     \"text\",\n",
    "                  \"analyzer\": \"english\",\n",
    "                  \"tokenizer\": {\n",
    "                    \"ngram_token\": {\n",
    "                      \"type\": \"ngram\",\n",
    "                      \"min_gram\": 1,\n",
    "                      \"max_gram\": 3,\n",
    "                      \"token_chars\": [\n",
    "                        \"whitespace\",\n",
    "                        \"punctuation\"\n",
    "                      ]\n",
    "                    }\n",
    "                  }\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"text_y\": { \n",
    "              \"type\": \"text\",\n",
    "              \"fields\": {\n",
    "                \"english\": { \n",
    "                  \"type\":     \"text\",\n",
    "                  \"analyzer\": \"english\",\n",
    "                  \"tokenizer\": {\n",
    "                    \"ngram_token\": {\n",
    "                      \"type\": \"ngram\",\n",
    "                      \"min_gram\": 1,\n",
    "                      \"max_gram\": 3,\n",
    "                      \"token_chars\": [\n",
    "                        \"whitespace\",\n",
    "                        \"punctuation\"\n",
    "                      ]\n",
    "                    }\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"context\": { \n",
    "              \"type\": \"text\",\n",
    "              \"fields\": {\n",
    "                \"english\": { \n",
    "                  \"type\":     \"text\",\n",
    "                  \"analyzer\": \"english\",\n",
    "                  \"tokenizer\": {\n",
    "                    \"ngram_token\": {\n",
    "                      \"type\": \"ngram\",\n",
    "                      \"min_gram\": 1,\n",
    "                      \"max_gram\": 3,\n",
    "                      \"token_chars\": [\n",
    "                        \"whitespace\",\n",
    "                        \"punctuation\"\n",
    "                      ]\n",
    "                    }\n",
    "                }\n",
    "              }\n",
    "            },\n",
    "            \"author\": { \n",
    "              \"type\": \"text\"\n",
    "              }\n",
    "            }\n",
    "          }\n",
    "        }\n",
    "      }}'''\n",
    "\n",
    "    es.indices.create(index='test-index', ignore=400, body=mapping)\n",
    "\n",
    "\n",
    "def fill_index(es, text_x, text_y, batch=10000):\n",
    "    actions = []\n",
    "    for id, (tx, ty) in enumerate(zip(text_x, text_y)):\n",
    "        doc = create_doc(tx, ty, '', 'AppleSupport')\n",
    "        #res = es.index(index=\"test-index\", doc_type='tweet', id=id, body=doc)\n",
    "\n",
    "        action = {\n",
    "            \"_index\": \"test-index\",\n",
    "            \"_type\": \"tweet\",\n",
    "            #\"_id\": id,\n",
    "            \"_source\": doc\n",
    "        }\n",
    "        actions.append(action)\n",
    "        if (len(actions) == batch):\n",
    "            print(\"Pushed {} rows\".format(len(actions)))\n",
    "            helpers.bulk(es, actions)\n",
    "            del actions[:]\n",
    "\n",
    "    if (len(actions) > 0):\n",
    "        helpers.bulk(es, actions)\n",
    "\n",
    "\n",
    "def query_es(text_x, num_hits = 1, is_array = True, query_field = 'text_x'):\n",
    "    if (is_array):\n",
    "        text_x = from_word_idx(text_x)\n",
    "\n",
    "    #res = es.search(index=\"test-index\", body={\"query\": {\"match\": { \"text_x\": text_x }}, 'from': 1, 'size': 10})\n",
    "    res = es.search(\n",
    "        index=\"test-index\",\n",
    "        body={\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"should\": [{\n",
    "                        \"match\": {\n",
    "                            query_field: {\n",
    "                                \"query\": text_x,\n",
    "                                \"boost\": 1\n",
    "                            }\n",
    "                        }\n",
    "                    }, {\n",
    "                        \"match\": {\n",
    "                            \"context\": {\n",
    "                                \"query\": '',\n",
    "                                \"boost\": 1\n",
    "                            }\n",
    "                        }\n",
    "                    }]\n",
    "                }\n",
    "            },\n",
    "            'from': 0,\n",
    "            'size': num_hits\n",
    "        })\n",
    "    \n",
    "    scores = [hit['_score'] for hit in res['hits']['hits']]\n",
    "    \n",
    "    #idx = np.random.choice(list(range(len(scores))), p = scores / np.sum(scores))\n",
    "    #res = es.search(index=\"test-index\", body={\"query\": {\"more_like_this\": { \"fields\": ['text_x'] , 'like': text_x}}})\n",
    "    #res = es.search(index=\"test-index\", body={\"query\": {\"match\": { \"text_x\": text_x }}, 'from': 1, 'size': 10})\n",
    "\n",
    "    return [(x['_source']['text_x'], x['_source']['text_y']) for x in res['hits']['hits']]\n",
    "\n",
    "def query_es_bulk(texts_x, num_hits = 1, is_array = True, query_field = 'text_x'):\n",
    "    if (is_array):\n",
    "        texts_x = from_word_idx(texts_x)\n",
    "\n",
    "    bodies = []\n",
    "    for text_x in texts_x:\n",
    "        bodies.append({\"index\": \"test-index\", \"type\": \"tweet\"},)\n",
    "        bodies.append({\n",
    "            \"query\": {\n",
    "                \"bool\": {\n",
    "                    \"should\": [{\n",
    "                        \"match\": {\n",
    "                            query_field: {\n",
    "                                \"query\": text_x,\n",
    "                                \"boost\": 5\n",
    "                            }\n",
    "                        }\n",
    "                    }, {\n",
    "                        \"match\": {\n",
    "                            \"context\": {\n",
    "                                \"query\": '',\n",
    "                                \"boost\": 1\n",
    "                            }\n",
    "                        }\n",
    "                    }]\n",
    "                }\n",
    "            },\n",
    "            #'from': 0,\n",
    "            'size': num_hits\n",
    "        })\n",
    "    res = es.msearch(bodies)\n",
    "    \n",
    "    return [[x['_source']['text_y'] for x in r['hits']['hits']] for r in res['responses']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch()\n",
    "if not es.indices.exists(index=\"test-index\"):\n",
    "    create_index(es)\n",
    "    fill_index(es, train_x, train_y, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ae266fe78646ccbf48514ba3b1a539",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=4044), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "references = []\n",
    "hypothesis = []\n",
    "\n",
    "for i in tqdm(range(len(test_x))):\n",
    "    #r = voc_holder.to_word_idx(, -1)\n",
    "    ref = test_y.iloc[i]\n",
    "    question = test_x.iloc[i][:1000]\n",
    "    try:\n",
    "        a_text = query_es(question, is_array=False)[0][1]\n",
    "    except:\n",
    "        a_text = ''\n",
    "    \n",
    "    #references.append(strip_punkt(voc_holder.to_word_idx(ref, -1), eval_conf.voc_holder.reverse_vocab))\n",
    "    #hypothesis.append(strip_punkt(voc_holder.to_word_idx(a_text, -1), eval_conf.voc_holder.reverse_vocab))\n",
    "    r = voc_holder.to_word_idx(ref, -1)\n",
    "    h = voc_holder.to_word_idx(a_text, -1)\n",
    "    references.append(r[r.nonzero()])\n",
    "    hypothesis.append(h[h.nonzero()])\n",
    "\n",
    "    \n",
    "references = np.array(references)\n",
    "hypothesis = np.array(hypothesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU@2: 13.732301176466532\n",
      "Embedding Average: 96.8846297555305\n",
      "Greedy Matching: 61.66439341050898\n",
      "ROUGE_L: 22.347860605005877\n",
      "Vector Extrema: 52.44791511076616\n"
     ]
    }
   ],
   "source": [
    "eval_conf = get_evaluation_conf(None, hparams, None, None, voc_holder)\n",
    "evaluation = evaluate_words_index(references, hypothesis, eval_conf, hparams.evaluation_metrics, True)\n",
    "print(format_metrics(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Average: 97.53525121210514\n",
      "Embedding Average: 97.53525121210514\n",
      "Embedding Average: 97.53525121210514\n"
     ]
    }
   ],
   "source": [
    "eval_conf = get_evaluation_conf(None, hparams, None, None, voc_holder)\n",
    "r = [references[1], references[200], references[3]]\n",
    "h = [hypothesis[1], hypothesis[200], hypothesis[3]]\n",
    "evaluation = evaluate_words_index(r, h, eval_conf, [\"embedding_average\"], True)\n",
    "print(format_metrics(evaluation))\n",
    "\n",
    "r = [references[200], references[1], references[3]]\n",
    "h = [hypothesis[200], hypothesis[1], hypothesis[3]]\n",
    "evaluation = evaluate_words_index(r, h, eval_conf, [\"embedding_average\"], True)\n",
    "print(format_metrics(evaluation))\n",
    "\n",
    "r = [references[3], references[200], references[1]]\n",
    "h = [hypothesis[3], hypothesis[200], hypothesis[1]]\n",
    "\n",
    "evaluation = evaluate_words_index(r, h, eval_conf, [\"embedding_average\"], True)\n",
    "print(format_metrics(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'stop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-4f76a9dad686>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"
     ]
    }
   ],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_conf = get_evaluation_conf(None, hparams, None, None, voc_holder)\n",
    "evaluation = evaluate_words_index(references, hypothesis, eval_conf, [\"embedding_average\"], True)\n",
    "print(format_metrics(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_conf = get_evaluation_conf(None, hparams, None, None, voc_holder)\n",
    "r = [references[1], references[200], references[3]]\n",
    "h = [hypothesis[1], hypothesis[200], hypothesis[3]]\n",
    "evaluation = evaluate_words_index(r, h, eval_conf, [\"embedding_average\"], True)\n",
    "print(format_metrics(evaluation))\n",
    "\n",
    "r = [references[200], references[1], references[3]]\n",
    "h = [hypothesis[200], hypothesis[1], hypothesis[3]]\n",
    "evaluation = evaluate_words_index(r, h, eval_conf, [\"embedding_average\"], True)\n",
    "print(format_metrics(evaluation))\n",
    "\n",
    "r = [references[3], references[200], references[1]]\n",
    "h = [hypothesis[3], hypothesis[200], hypothesis[1]]\n",
    "\n",
    "evaluation = evaluate_words_index(r, h, eval_conf, [\"embedding_average\"], True)\n",
    "print(format_metrics(evaluation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#answer = '<user> every time i restart my <version> phone i get sms notifications from years ago , then 1/2 the time the home screen stops working . backup restore and happening on my iphone x now too <url>'\n",
    "#answer = 'ah so when it is apple going to update xcode with <version> support ? updated my iphone 6s and now cannot build my project for my device . thanks <user>'\n",
    "answer = '<user> i have updated my <hashtag> to <hashtag> . 2 and i am not seeing the apple pay cash ! i live in us'\n",
    "ir_answers = query_es(answer,\n",
    "        5, False, 'text_x')\n",
    "print(answer)\n",
    "print()\n",
    "print('\\n\\n'.join(map(lambda x: '>>>>> ' +x[0] + '\\n<<<<< ' + x[1], ir_answers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
